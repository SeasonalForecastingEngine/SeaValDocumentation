<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Validation |  The SeaVal package for validating seasonal weather forecasts</title>
  <meta name="description" content="<br />
The <code>SeaVal</code> package for validating seasonal weather forecasts</p>" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Validation |  The SeaVal package for validating seasonal weather forecasts" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Validation |  The SeaVal package for validating seasonal weather forecasts" />
  
  
  

<meta name="author" content="Claudio Heinrich and Michael Scheuerer, with input from" />
<meta name="author" content="Masilin Gudoshava, Eunice Koech, Anthony Mwanthi, Zewdu Segele, Hussen Seid and Thordis Thorarinsdottir" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-import-and-processing-1.html"/>
<link rel="next" href="validation-1.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting Started</a>
<ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#installation"><i class="fa fa-check"></i><b>1.1</b> Installation</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#examples-of-data.table-syntax"><i class="fa fa-check"></i><b>1.2</b> examples of <code>data.table</code> syntax</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>2</b> Plotting</a>
<ul>
<li class="chapter" data-level="2.1" data-path="plotting.html"><a href="plotting.html#plotting-values-for-selected-countries"><i class="fa fa-check"></i><b>2.1</b> Plotting values for selected countries</a></li>
<li class="chapter" data-level="2.2" data-path="plotting.html"><a href="plotting.html#customized-plots"><i class="fa fa-check"></i><b>2.2</b> Customized plots</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-import-and-processing.html"><a href="data-import-and-processing.html"><i class="fa fa-check"></i><b>3</b> Data import and processing</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-import-and-processing.html"><a href="data-import-and-processing.html#netcdf_to_dt"><i class="fa fa-check"></i><b>3.1</b> The function <code>netcdf_to_dt</code></a></li>
<li class="chapter" data-level="3.2" data-path="data-import-and-processing.html"><a href="data-import-and-processing.html#chirps"><i class="fa fa-check"></i><b>3.2</b> Downloading and processing CHIRPS data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-import-and-processing-1.html"><a href="data-import-and-processing-1.html"><i class="fa fa-check"></i><b>4</b> Data import and processing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-import-and-processing-1.html"><a href="data-import-and-processing-1.html#data-examples"><i class="fa fa-check"></i><b>4.1</b> Reshaping data</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="data-import-and-processing-1.html"><a href="data-import-and-processing-1.html#cv-data"><i class="fa fa-check"></i><b>4.1.1</b> Example: cross-validation data</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-import-and-processing-1.html"><a href="data-import-and-processing-1.html#us-obs"><i class="fa fa-check"></i><b>4.1.2</b> Example: Tercile forecasts and upscaling</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-import-and-processing-1.html"><a href="data-import-and-processing-1.html#ex-corrupted-netcdf"><i class="fa fa-check"></i><b>4.1.3</b> Example: ‘corrupted’ netcdf</a></li>
<li class="chapter" data-level="4.1.4" data-path="data-import-and-processing-1.html"><a href="data-import-and-processing-1.html#data-ex-prexc"><i class="fa fa-check"></i><b>4.1.4</b> Example: preparing data for evaluating exceedence probabilities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="validation.html"><a href="validation.html"><i class="fa fa-check"></i><b>5</b> Validation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="validation.html"><a href="validation.html#cv-eval"><i class="fa fa-check"></i><b>5.1</b> Evaluating cross-validation predictions</a></li>
<li class="chapter" data-level="5.2" data-path="validation.html"><a href="validation.html#evaluating-tercile-forecasts"><i class="fa fa-check"></i><b>5.2</b> Evaluating Tercile Forecasts</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="validation.html"><a href="validation.html#eval-terciles"><i class="fa fa-check"></i><b>5.2.1</b> Proper scoring rules for full tercile forecasts</a></li>
<li class="chapter" data-level="5.2.2" data-path="validation.html"><a href="validation.html#eval-terciles2"><i class="fa fa-check"></i><b>5.2.2</b> Evaluation when only the highest probability category is avaliable</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="validation.html"><a href="validation.html#eval-ex-pr"><i class="fa fa-check"></i><b>5.3</b> Exceedence probabilities</a></li>
<li class="chapter" data-level="5.4" data-path="validation.html"><a href="validation.html#temperature"><i class="fa fa-check"></i><b>5.4</b> Temperature</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="validation-1.html"><a href="validation-1.html"><i class="fa fa-check"></i><b>6</b> Validation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="validation-1.html"><a href="validation-1.html#upscaling"><i class="fa fa-check"></i><b>6.1</b> Matching predictions and observations</a></li>
<li class="chapter" data-level="6.2" data-path="validation-1.html"><a href="validation-1.html#evaluating-weekly-predictions-of-precipitation"><i class="fa fa-check"></i><b>6.2</b> Evaluating weekly predictions of precipitation</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p><img src="logo_CONFER.png" style="width:2in" /><br />
The <code>SeaVal</code> package for validating seasonal weather forecasts</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="validation" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Validation</h1>
<p>In this section we look into validating different types of predictions. Our focus herby lies on proper scoring rules, as well as skill scores for comparison to climatology.</p>
<div id="cv-eval" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Evaluating cross-validation predictions</h2>
<p>Here we evaluate the cross-validation data prepared in Section <a href="data-import-and-processing-1.html#cv-data">4.1.1</a>.
The data table contains observations for past years for the FMA season, along with ‘best-guess’-predictions, meaning that they are single numbers, not probabilities:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="validation.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dt_cv)</span></code></pre></div>
<pre><code>##         lon   lat prediction observation year month
##     1: 20.5 -11.5  316.19452   369.36932 1982     2
##     2: 20.5 -11.5  316.20178   252.47144 1983     2
##     3: 20.5 -11.5  317.43375   267.44031 1984     2
##     4: 20.5 -11.5  313.30789   332.10236 1985     2
##     5: 20.5 -11.5  318.12195   343.65460 1986     2
##    ---                                             
## 79745: 51.5  22.5   25.44651    19.71902 2012     2
## 79746: 51.5  22.5   25.59836    27.55773 2013     2
## 79747: 51.5  22.5   26.03941    25.14965 2014     2
## 79748: 51.5  22.5   26.03053    22.23634 2015     2
## 79749: 51.5  22.5   26.00327    34.84376 2016     2</code></pre>
<p>Such predictions are often called <em>point forecasts</em>, whereas forecasts specifying probabilities are called <em>probabilistic</em>.
We already have the data in the shape we want it to be, containing both predictions and observations as one column each. Let’s have a look at the bias in our predictions:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="validation.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="do">### check out local biases:</span></span>
<span id="cb144-2"><a href="validation.html#cb144-2" aria-hidden="true" tabindex="-1"></a>bias_dt <span class="ot">=</span> dt_cv[,.(<span class="at">bias =</span> <span class="fu">mean</span>(prediction <span class="sc">-</span> observation)), by <span class="ot">=</span> .(lon,lat)] <span class="co"># grouping by lon,lat, and season means that the mean is taken over all years.</span></span>
<span id="cb144-3"><a href="validation.html#cb144-3" aria-hidden="true" tabindex="-1"></a>bias_dt[,<span class="fu">range</span>(bias)] <span class="co"># get an idea of the range for plotting</span></span></code></pre></div>
<pre><code>## [1] -10.81321  13.11778</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="validation.html#cb146-1" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">15</span>,<span class="dv">15</span>) <span class="co"># fix range, to make plots comparable</span></span>
<span id="cb146-2"><a href="validation.html#cb146-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-3"><a href="validation.html#cb146-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">ggplot_dt</span>(bias_dt,</span>
<span id="cb146-4"><a href="validation.html#cb146-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">data_col =</span> <span class="st">&#39;bias&#39;</span>, </span>
<span id="cb146-5"><a href="validation.html#cb146-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">rr =</span> rr, <span class="co"># fix range to make it comparable to pp2</span></span>
<span id="cb146-6"><a href="validation.html#cb146-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">mn =</span> <span class="st">&#39;bias of FMA prediction&#39;</span>,</span>
<span id="cb146-7"><a href="validation.html#cb146-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">midpoint =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-2-1.png" width="960" /></p>
<p>For evaluating the locally varying skill of these predictions we can calculate the average square error per location and compare it to the square error we would get by predicting local climatology, i.e., just the mean precipitation for that location. This is called the mean square error skill score (MSES) and is calculated by the function <code>MSES</code>.
For fair comparison, the climatology needs to be calculated leave-one-year-out: For example, a climatological prediction for 2021 prediction would be the mean precipitation over all years <em>except 2021</em>. Otherwise, the climatological forecast uses information that would not be available in a prediction setting, which inflates the skill of the climatology forecast.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="validation.html#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="do">### analyze mean square error skill scores</span></span>
<span id="cb147-2"><a href="validation.html#cb147-2" aria-hidden="true" tabindex="-1"></a>msess <span class="ot">=</span> <span class="fu">MSES</span>(dt_cv,</span>
<span id="cb147-3"><a href="validation.html#cb147-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">f =</span> <span class="st">&#39;prediction&#39;</span>, <span class="co"># column name of forecasts</span></span>
<span id="cb147-4"><a href="validation.html#cb147-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">o =</span> <span class="st">&#39;observation&#39;</span>, <span class="co"># column name of observations</span></span>
<span id="cb147-5"><a href="validation.html#cb147-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&#39;lon&#39;</span>,<span class="st">&#39;lat&#39;</span>)) <span class="co"># the skill scores should be computed for each location separately</span></span>
<span id="cb147-6"><a href="validation.html#cb147-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-7"><a href="validation.html#cb147-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot results:</span></span>
<span id="cb147-8"><a href="validation.html#cb147-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot_dt</span>(msess,</span>
<span id="cb147-9"><a href="validation.html#cb147-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">data_col =</span> <span class="st">&#39;MSES&#39;</span>, </span>
<span id="cb147-10"><a href="validation.html#cb147-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">midpoint =</span> <span class="dv">0</span>, <span class="co"># center color scale, white is 0</span></span>
<span id="cb147-11"><a href="validation.html#cb147-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">mn =</span> <span class="st">&#39;MSE skill score, FMA&#39;</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-3-1.png" width="960" />
As for all skill scores, positive values indicate that the prediction has higher skill than climatology, negative values indicates lower skill. Skill scores are moreover ‘standardized’ such that a score of 1 corresponds to a perfect forecast.
Most evaluation functions in <code>SeaVal</code> require similar input as <code>MSES</code>:
* <code>dt</code>: a data table containing both observations and predictions.
* <code>f</code>,<code>o</code>: the column names of the predictions and observation.
* <code>by</code>: the column names for dimension variables to group by.
[Add more context here]
Note that there is also a (faster) function <code>MSE</code> if we’re not interested in skill scores, but simply want to compute MSEs. Both function can also handle ensemble predictions, see function documentation.
If we want to analyze results by countries, we can use the function <code>add_country_names</code> that adds a column with country names to the data table:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="validation.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check out average MSEs and MSESSs per country:</span></span>
<span id="cb148-2"><a href="validation.html#cb148-2" aria-hidden="true" tabindex="-1"></a>msess <span class="ot">=</span> <span class="fu">add_country_names</span>(msess)</span>
<span id="cb148-3"><a href="validation.html#cb148-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(msess)</span></code></pre></div>
<pre><code>##        lon  lat       MSE  clim_MSE          MSES     country
##    1: 24.5  8.5 166.01823 160.95057 -0.0314858375 South Sudan
##    2: 25.0  8.0 157.70201 155.21241 -0.0160399415 South Sudan
##    3: 25.0  8.5 184.12923 175.97631 -0.0463296523 South Sudan
##    4: 25.5  7.5 318.41059 315.81470 -0.0082196638 South Sudan
##    5: 25.5  8.0 189.80862 189.96845  0.0008413415 South Sudan
##   ---                                                        
## 1231: 48.5 11.0  68.40813  72.26785  0.0534084478     Somalia
## 1232: 49.0  6.5 202.11711 216.18040  0.0650534734     Somalia
## 1233: 49.0  7.0 153.96742 162.97361  0.0552616643     Somalia
## 1234: 49.5 11.0  74.21040  76.48522  0.0297419712     Somalia
## 1235: 50.0 11.0 181.27647 184.42122  0.0170519749     Somalia</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="validation.html#cb150-1" aria-hidden="true" tabindex="-1"></a>msess_by_country <span class="ot">=</span> msess[,.(<span class="at">MSE =</span> <span class="fu">mean</span>(MSE),</span>
<span id="cb150-2"><a href="validation.html#cb150-2" aria-hidden="true" tabindex="-1"></a>                            <span class="at">MSES =</span> <span class="fu">mean</span>(MSES)), by <span class="ot">=</span> country] <span class="co"># take averages by country</span></span>
<span id="cb150-3"><a href="validation.html#cb150-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-4"><a href="validation.html#cb150-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(msess_by_country)</span></code></pre></div>
<pre><code>##         country       MSE         MSES
##  1: South Sudan  622.6657  0.029073419
##  2:      Rwanda 1695.8937  0.130467978
##  3:    Tanzania 4011.6931  0.030148166
##  4:     Burundi 2195.6404  0.109954193
##  5:      Uganda 1369.9684  0.062205385
##  6:    Ethiopia 1557.5682  0.068145290
##  7:       Kenya 2173.5858  0.066719651
##  8:       Sudan  216.8926 -0.021270474
##  9:     Eritrea  393.7713  0.007646318
## 10:     Somalia 1183.0632  0.040397831
## 11:    Djibouti  121.1750  0.078021693</code></pre>
<p>Skill scores strongly depend on the skill of the climatological prediction, see Section <a href="validation.html#eval-ex-pr">5.3</a>. This makes it somewhat problematic to average them in space, as skill scores for different grid points with different climatologies have different meanings. A more appropriate way to see whether the prediction outperformed climatology on average for a given country is by considering average score differences:</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="validation.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># positive values indicate better performance than climatology:</span></span>
<span id="cb152-2"><a href="validation.html#cb152-2" aria-hidden="true" tabindex="-1"></a>msess[,.(<span class="at">score_diff =</span> <span class="fu">mean</span>(clim_MSE <span class="sc">-</span> MSE)),by <span class="ot">=</span> country]</span></code></pre></div>
<pre><code>##         country score_diff
##  1: South Sudan  27.289033
##  2:      Rwanda 283.252101
##  3:    Tanzania  82.175135
##  4:     Burundi 273.488506
##  5:      Uganda  89.460627
##  6:    Ethiopia 131.532177
##  7:       Kenya 166.101084
##  8:       Sudan  -4.517323
##  9:     Eritrea  -5.201654
## 10:     Somalia  58.001462
## 11:    Djibouti  11.940107</code></pre>
<p>The MSE (and its associated skill score) penalizes both systematic forecast errors (i.e. biases) and non-systematic forecast errors. The latter are a consequence of general forecast uncertainty and there is no easy way to reduce them. Biases, however, can often be removed through statistical post-processing, and it is therefore interesting to consider measures for forecast performance that penalize only non-systematic forecast errors, thus giving an idea of the <em>potential skill</em> of a forecast system.</p>
<p>The standard metric to assess the <em>potential skill</em> is the <em>Pearson correlation coefficient (PCC)</em>. This is the usual correlation coefficient where forecasts and observations are standardized by their respective climatological means and standard deviations, and then the average product of these standardized variables is calculated. The function <code>PCC</code> performs these calculations and is used in the same way as <code>MSES</code> above.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="validation.html#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="do">### calculate Pearson correlation coefficients</span></span>
<span id="cb154-2"><a href="validation.html#cb154-2" aria-hidden="true" tabindex="-1"></a>pcc <span class="ot">=</span> <span class="fu">PCC</span>(dt_cv,</span>
<span id="cb154-3"><a href="validation.html#cb154-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">f =</span> <span class="st">&#39;prediction&#39;</span>, <span class="co"># column name of forecasts</span></span>
<span id="cb154-4"><a href="validation.html#cb154-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">o =</span> <span class="st">&#39;observation&#39;</span>, <span class="co"># column name of observations</span></span>
<span id="cb154-5"><a href="validation.html#cb154-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&#39;lon&#39;</span>,<span class="st">&#39;lat&#39;</span>)) <span class="co"># the correlation coefficient should be computed for each location separately</span></span>
<span id="cb154-6"><a href="validation.html#cb154-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-7"><a href="validation.html#cb154-7" aria-hidden="true" tabindex="-1"></a><span class="co"># the maximal range for a correlation coefficient is [-1,1], but sometimes it is useful to narrow it:</span></span>
<span id="cb154-8"><a href="validation.html#cb154-8" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.75</span>,<span class="fl">0.75</span>)</span>
<span id="cb154-9"><a href="validation.html#cb154-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-10"><a href="validation.html#cb154-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot_dt</span>(pcc,</span>
<span id="cb154-11"><a href="validation.html#cb154-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">data_col =</span> <span class="st">&#39;rho&#39;</span>, </span>
<span id="cb154-12"><a href="validation.html#cb154-12" aria-hidden="true" tabindex="-1"></a>          <span class="at">rr=</span>rr,</span>
<span id="cb154-13"><a href="validation.html#cb154-13" aria-hidden="true" tabindex="-1"></a>          <span class="at">mn =</span> <span class="st">&#39;Pearson correlation coefficient, FMA&#39;</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-6-1.png" width="960" /></p>
<p>While there is no technical requirement that the forecasts and observations follow a particular probability distribution when the Pearson correlation coefficient is employed, this metric is best suited for continuous distributions (i.e. it is unlikely to encounter duplicate values) that are relatively symmetric around the mean. For shorter (e.g. weekly) accumulation periods and in dry climates, the distribution of precipitation usually becomes rather skewed and contains a number of zeros. A new metric, the coefficient of predictive ability (CPA), has recently been developed and constitutes an excellent alternative to the PCC as a measure of potential forecast skill in that situation of strongly asymmetric distributions with multiple identical values. See <a href="MotivationCPA.pdf">here</a> for more background information about the CPA. The function <code>CPA</code> performs the calculations and is used in the same way as <code>MSES</code> and <code>PCC</code> above.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="validation.html#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="do">### calculate coefficient of predictive ability</span></span>
<span id="cb155-2"><a href="validation.html#cb155-2" aria-hidden="true" tabindex="-1"></a>cpa <span class="ot">=</span> <span class="fu">CPA</span>(dt_cv,</span>
<span id="cb155-3"><a href="validation.html#cb155-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">f =</span> <span class="st">&#39;prediction&#39;</span>, <span class="co"># column name of forecasts</span></span>
<span id="cb155-4"><a href="validation.html#cb155-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">o =</span> <span class="st">&#39;observation&#39;</span>, <span class="co"># column name of observations</span></span>
<span id="cb155-5"><a href="validation.html#cb155-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&#39;lon&#39;</span>,<span class="st">&#39;lat&#39;</span>)) <span class="co"># the CPA should be computed for each location separately</span></span>
<span id="cb155-6"><a href="validation.html#cb155-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-7"><a href="validation.html#cb155-7" aria-hidden="true" tabindex="-1"></a><span class="co"># the maximal range for the CPA is [0,1]</span></span>
<span id="cb155-8"><a href="validation.html#cb155-8" aria-hidden="true" tabindex="-1"></a><span class="co"># a value of 0.5 corresponds to no skill (more details can be found in the document under the link given above) </span></span>
<span id="cb155-9"><a href="validation.html#cb155-9" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb155-10"><a href="validation.html#cb155-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-11"><a href="validation.html#cb155-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot_dt</span>(cpa, </span>
<span id="cb155-12"><a href="validation.html#cb155-12" aria-hidden="true" tabindex="-1"></a>          <span class="at">data_col =</span> <span class="st">&#39;cpa&#39;</span>, </span>
<span id="cb155-13"><a href="validation.html#cb155-13" aria-hidden="true" tabindex="-1"></a>          <span class="at">rr=</span>rr,</span>
<span id="cb155-14"><a href="validation.html#cb155-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">mn =</span> <span class="st">&#39;Coefficient of predictive ability, FMA&#39;</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-7-1.png" width="960" /></p>
<p>Just like the MSES, PCC and CPA can be averaged by country using the function <code>add_country_names</code>:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="validation.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check out average PCCs and CPAs per country:</span></span>
<span id="cb156-2"><a href="validation.html#cb156-2" aria-hidden="true" tabindex="-1"></a>pcc <span class="ot">=</span> <span class="fu">add_country_names</span>(pcc)</span>
<span id="cb156-3"><a href="validation.html#cb156-3" aria-hidden="true" tabindex="-1"></a>cpa <span class="ot">=</span> <span class="fu">add_country_names</span>(cpa)</span>
<span id="cb156-4"><a href="validation.html#cb156-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-5"><a href="validation.html#cb156-5" aria-hidden="true" tabindex="-1"></a>pcc_by_country <span class="ot">=</span> pcc[,.(<span class="at">rho =</span> <span class="fu">mean</span>(rho)), by <span class="ot">=</span> country]</span>
<span id="cb156-6"><a href="validation.html#cb156-6" aria-hidden="true" tabindex="-1"></a>cpa_by_country <span class="ot">=</span> cpa[,.(<span class="at">cpa =</span> <span class="fu">mean</span>(cpa)), by <span class="ot">=</span> country]</span>
<span id="cb156-7"><a href="validation.html#cb156-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-8"><a href="validation.html#cb156-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pcc_by_country)</span></code></pre></div>
<pre><code>##         country          rho
##  1: South Sudan -0.131322590
##  2:      Rwanda  0.304516201
##  3:    Tanzania -0.102200872
##  4:     Burundi  0.230229774
##  5:      Uganda  0.087081218
##  6:    Ethiopia  0.068491179
##  7:       Kenya  0.100172850
##  8:       Sudan -0.328970736
##  9:     Eritrea -0.169954159
## 10:     Somalia  0.003777202
## 11:    Djibouti  0.194408707</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="validation.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cpa_by_country)</span></code></pre></div>
<pre><code>##         country       cpa
##  1: South Sudan 0.4362882
##  2:      Rwanda 0.6468312
##  3:    Tanzania 0.4564792
##  4:     Burundi 0.6117025
##  5:      Uganda 0.5372199
##  6:    Ethiopia 0.5428733
##  7:       Kenya 0.5474916
##  8:       Sudan 0.3812325
##  9:     Eritrea 0.4131719
## 10:     Somalia 0.5254189
## 11:    Djibouti 0.6097689</code></pre>
</div>
<div id="evaluating-tercile-forecasts" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Evaluating Tercile Forecasts</h2>
<p>Next, we’ll turn our attention to one of the main products disseminated at GHACOFs, the probabilistic forecasts whether the coming season will see a below normal-, normal-, or above normal amount of rainfall. Since these three categories are defined by climatological terciles, we call them tercile forecasts. From an evaluation perspective, there are two different scenarios: Either we get the prediction as a vector of three probabilities, or we just get the probability for the most likely category. Evaluating a vector of three probabilities is preferrable, because it conveys more detailed information about the forecast: Say, for example, two competing models predicted the probabilities (0.5, 0.3, 0.2) and (0.5, 0.49, 0.01), respectively (in the order below, normal, high). Say now, after observing the predicted season, it turns out that the rainfall was in fact above normal. In this case, both predictions were pretty bad, but the first model at least assigned a 20% chance to above-normal-rainfall, whereas the second model only assigned a 1% chance to that outcome. So the first prediction was substantially better. However, if we only look at the category with the highest predicted probability, the two models can’t be distinguished, as they both appear as (0.5,-,-).</p>
<p>Therefore, considering all three probabilities of the prediction allows for better forecast evaluation. This does not mean, however, that the communication of the prediction to the public needs to contain all three probabilities, which would likely be more confusing than helpful. In the next subsection we’ll discuss how to evaluate a fully probability forecast (vector of three probabilities). In the section thereafter, we address the case where only the most likely category is known.</p>
<div id="eval-terciles" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Proper scoring rules for full tercile forecasts</h3>
<p>Proper scoring rules are tools for evaluating predictive performance. Given a prediction and the corresponding observation, a proper score returns a single number. We consider negatively oriented scores, that is, lower scores indicate better performance. Popular examples are the Brier Score, Mean Square Error (MSE), Log-likelihood score or the continuous ranked probability score (CRPS).</p>
<p>When we’re dealing with tercile forecasts of precipitation, we can use the <em>Multicategory Brier Score (MBS)</em>. It is defined as
<span class="math display">\[\text{MBS} :=  (p_1 - e_1)^2 + (p_2 - e_2)^2 + (p_3 - e_3)^2.\]</span>
Here, <span class="math inline">\(p_1,p_2,\)</span> and <span class="math inline">\(p_3\)</span> are the predicted probabilities for the three categories, and <span class="math inline">\(e_i\)</span> is 1 if the observation falls in the <span class="math inline">\(i\)</span>th category, and 0 else. For example, if the observation falls into the first category, the MBS would be
<span class="math display">\[(p_1 - 1)^2 + p_2^2 + p_3^2.\]</span></p>
<p>This score is strictly proper, meaning that it rewards calibration and accuracy. In our particular situation, the climatological forecast is uniform
(since climatology is used to define the tercile categories), and the climatological forecast (1/3,1/3,1/3) always gets a MBS of 2/3.
It is therefore very convenient to consider the <em>Multicategory Brier Skill Score (MBSS)</em>
<span class="math display">\[MBSS := \frac{3}{2}(2/3 - \text{MBS}).\]</span>
Like other skill scores, this score is normalized in the sense that a perfect forecaster attains a skill score of 1 and a climatology forecast always gets a skill score of 0.
Note that, for the MBSS, higher values indicate better performance, unlike for the MBS (similar as for other scores such as MSE).</p>
<p>Tercile forecasts are a particular situation where the skill score is a strictly proper scoring rule itself (albeit positively oriented). This means in particular that we may average Multicategory Brier Skill Scores accross different grid points without being concerned about different scales of precipitation.
If, for example, the average MBSS of our prediction over all gridpoints in Ethiopia is above 0, our prediction for Ethiopia was on average better than climatology.</p>
<p>Let’s now look at a data example, contained in the <code>data_dir</code> specified <a href="data-import-and-processing.html#netcdf_to_dt">here</a>. The core function is simply called <code>MBSS_dt</code>. The main work is organizing the data in one data table of the correct format, which was done in Section <a href="data-import-and-processing-1.html#us-obs">4.1.2</a>. In particular, recall that we can use the function <code>add_tercile_cat</code> to determine which observations are in the lower or upper climatology tercile.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="validation.html#cb160-1" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">=</span> dt_tercile_forecast</span>
<span id="cb160-2"><a href="validation.html#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dt)</span></code></pre></div>
<pre><code>##        lon   lat    normal     above     below year    precip tercile_cat
##    1: 22.0 -11.5 0.2794044 0.3959641 0.3246315 2021 271.66260          -1
##    2: 22.0 -11.0 0.3176142 0.3509704 0.3314154 2021 279.14212          -1
##    3: 22.0 -10.5 0.2897301 0.3781255 0.3321443 2021 300.32638          -1
##    4: 22.0 -10.0 0.3133837 0.3520903 0.3345260 2021 332.45747           0
##    5: 22.0  -9.5 0.3076811 0.3480890 0.3442299 2021 407.19511           1
##   ---                                                                    
## 3268: 51.5  20.0        NA        NA        NA 2021  26.43543           1
## 3269: 51.5  20.5        NA        NA        NA 2021  25.20967           1
## 3270: 51.5  21.0        NA        NA        NA 2021  21.71081           0
## 3271: 51.5  21.5        NA        NA        NA 2021  23.18161           0
## 3272: 51.5  22.0        NA        NA        NA 2021  23.29284          -1
##            clim
##    1: 311.90872
##    2: 331.75210
##    3: 333.75472
##    4: 335.87600
##    5: 350.41710
##   ---          
## 3268:  25.26015
## 3269:  24.40523
## 3270:  22.87279
## 3271:  24.11377
## 3272:  27.69789</code></pre>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="validation.html#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get Multicategory Brier Skill Score:</span></span>
<span id="cb162-2"><a href="validation.html#cb162-2" aria-hidden="true" tabindex="-1"></a>mbs <span class="ot">=</span> <span class="fu">MBS</span>(dt,</span>
<span id="cb162-3"><a href="validation.html#cb162-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">o =</span> <span class="st">&#39;tercile_cat&#39;</span>)</span>
<span id="cb162-4"><a href="validation.html#cb162-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot_dt</span>(mbs,<span class="at">high =</span> <span class="st">&#39;darkgreen&#39;</span>,<span class="at">low =</span> <span class="st">&#39;purple&#39;</span>,<span class="at">discrete_cs =</span> <span class="cn">TRUE</span>,<span class="at">binwidth =</span> <span class="fl">0.2</span>,<span class="at">midpoint =</span> <span class="dv">0</span>, <span class="at">mn =</span> <span class="st">&#39;MBS for MAM tercile forecast 2021&#39;</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-9-1.png" width="480" /></p>
<p>Areas colored in green show where the prediction was better than climatology, areas colored in purple indicate worse performance. The MBSS indicates, for example, good forecast performance over most of Tanzania.</p>
<p>To see whether the forecast was overall better than climatology, we average the MBS:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="validation.html#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check out the MBS by country:</span></span>
<span id="cb163-2"><a href="validation.html#cb163-2" aria-hidden="true" tabindex="-1"></a>mbs <span class="ot">=</span> <span class="fu">add_country_names</span>(mbs)</span>
<span id="cb163-3"><a href="validation.html#cb163-3" aria-hidden="true" tabindex="-1"></a>mean_mbs <span class="ot">=</span> mbs[,.(<span class="at">mean_mbs =</span> <span class="fu">mean</span>(MBS,<span class="at">na.rm =</span> T)), by <span class="ot">=</span> country]</span>
<span id="cb163-4"><a href="validation.html#cb163-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mean_mbs)</span></code></pre></div>
<pre><code>##         country    mean_mbs
##  1:       Sudan  0.02076894
##  2: South Sudan -0.01542756
##  3:      Rwanda  0.04052875
##  4:    Tanzania  0.01927918
##  5:     Burundi  0.09312281
##  6:      Uganda -0.02177326
##  7:    Ethiopia -0.02526435
##  8:       Kenya -0.02616993
##  9:     Eritrea -0.02673488
## 10:                     NaN
## 11:     Somalia -0.01600070
## 12:    Djibouti  0.03368777</code></pre>
<p>Finally, let’s check whether this makes sense, by comparing climatology to the prediction:</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="validation.html#cb165-1" aria-hidden="true" tabindex="-1"></a>dt[,anomaly<span class="sc">:</span><span class="er">=</span> precip <span class="sc">-</span> clim]</span>
<span id="cb165-2"><a href="validation.html#cb165-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb165-3"><a href="validation.html#cb165-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot_dt</span>(dt[year <span class="sc">==</span> <span class="dv">2021</span>],<span class="st">&#39;anomaly&#39;</span>,<span class="at">high =</span> <span class="st">&#39;blue&#39;</span>,<span class="at">low =</span> <span class="st">&#39;red&#39;</span>,<span class="at">midpoint =</span> <span class="dv">0</span>, <span class="at">mn =</span> <span class="st">&#39;observed 2021 MAM precip anomaly&#39;</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-11-1.png" width="480" /></p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="validation.html#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or, as discrete plot:</span></span>
<span id="cb166-2"><a href="validation.html#cb166-2" aria-hidden="true" tabindex="-1"></a>pp1 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt[year <span class="sc">==</span> <span class="dv">2021</span>],<span class="st">&#39;anomaly&#39;</span>,</span>
<span id="cb166-3"><a href="validation.html#cb166-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">high =</span> <span class="st">&#39;blue&#39;</span>,<span class="at">low =</span> <span class="st">&#39;red&#39;</span>,<span class="at">midpoint =</span> <span class="dv">0</span>,</span>
<span id="cb166-4"><a href="validation.html#cb166-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">rr =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>,<span class="dv">100</span>),<span class="at">discrete_cs =</span> <span class="cn">TRUE</span>,<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">100</span>,<span class="dv">100</span>,<span class="dv">40</span>),</span>
<span id="cb166-5"><a href="validation.html#cb166-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">mn =</span> <span class="st">&#39;observed 2021 MAM precip anomaly&#39;</span>)</span>
<span id="cb166-6"><a href="validation.html#cb166-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-7"><a href="validation.html#cb166-7" aria-hidden="true" tabindex="-1"></a><span class="co"># also, let&#39;s plot the predicted probabilities:</span></span>
<span id="cb166-8"><a href="validation.html#cb166-8" aria-hidden="true" tabindex="-1"></a>pp2 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt,<span class="st">&#39;below&#39;</span>,<span class="at">midpoint =</span> <span class="fl">0.33</span>,<span class="at">discrete_cs =</span> <span class="cn">TRUE</span>,<span class="at">binwidth =</span> <span class="fl">0.05</span>,<span class="at">mn =</span> <span class="st">&#39;predicted probability below&#39;</span>)</span>
<span id="cb166-9"><a href="validation.html#cb166-9" aria-hidden="true" tabindex="-1"></a>pp3 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt,<span class="st">&#39;normal&#39;</span>,<span class="at">midpoint =</span> <span class="fl">0.33</span>,<span class="at">discrete_cs =</span> <span class="cn">TRUE</span>,<span class="at">binwidth =</span> <span class="fl">0.05</span>,<span class="at">mn =</span> <span class="st">&#39;predicted probability normal&#39;</span>)</span>
<span id="cb166-10"><a href="validation.html#cb166-10" aria-hidden="true" tabindex="-1"></a>pp4 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt,<span class="st">&#39;above&#39;</span>,<span class="at">midpoint =</span> <span class="fl">0.33</span>,<span class="at">discrete_cs =</span> <span class="cn">TRUE</span>,<span class="at">binwidth =</span> <span class="fl">0.05</span>,<span class="at">mn =</span> <span class="st">&#39;predicted probability above&#39;</span>)</span>
<span id="cb166-11"><a href="validation.html#cb166-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-12"><a href="validation.html#cb166-12" aria-hidden="true" tabindex="-1"></a>ggpubr<span class="sc">::</span><span class="fu">ggarrange</span>(pp1,pp2,pp3,pp4,<span class="at">ncol =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-12-1.png" width="1920" />
As we can see, the season was very wet overall. The prediction was overall wet as well, especially over the western part of the considered region, where the prediction also got assigned a positive MBS.</p>
</div>
<div id="eval-terciles2" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Evaluation when only the highest probability category is avaliable</h3>
<p>As argued above, it is preferrable to evaluate tercile forecasts that are given as full probability vector containing all three probabilities. However, we might still face scenarios where we only have the highest probability category available, e.g. some older forecasts for which only this has been saved. What can we do in this case?</p>
<p>Intuitively, a promising candidate for a proper score seems to be the two-category-Brier score on the category with the highest probability
<span class="math display">\[BS_{\max} = (p_{\max}-e_{\max})^2,\]</span>
where <span class="math inline">\(p_{\max}\)</span> is the probability assigned to the maximum probability category, and <span class="math inline">\(e_{\max} = 1\)</span> if the observation falls into that category and <span class="math inline">\(0\)</span> else.
Unfortunately, it turns out that this score is <em>improper</em>: it does not reward calibration and accuracy. Let us look at an example forecast for just one gridpoint:</p>
<p><img src="example_plot.png" width="1210" /></p>
<p>In this example, we compare a near-climatological forecast (red) with a prediction issued by a forecaster (blue). The highest probability categories are indicated by the shaded area: for the forecaster it is the ‘above normal’ category, for the climatology-forecast the ‘below normal’ category. Below the figure, the scores achieved by the forecaster and climatology are shown for all three possible outcomes.
The climatology gets a better (lower) Brier score when the observation is ‘normal’ or ‘above normal’. This is paradoxical, since the forecaster assigned higher probabilities to these categorie. This highlights the improperness of the max-Brier score: When evaluating predictions with this score, the best forecast does usually not get preferred.</p>
<p>This is unintuitive, because the (standard) Brier score is proper. However, the Brier score is designed for predictions of two-category-events <em>with fixed categories</em>. In the definition of <span class="math inline">\(BS_{\max}\)</span> the categories are ‘highest probability category’ vs. the rest. Therefore, the two categories <em>depend on the forecast probabilities</em> and therefore may vary between different predictions. This makes the Brier score improper.</p>
<p>However, a nice application of Theorem 1 of <a href="https://arxiv.org/abs/1506.07212">this</a> paper shows that there is a class of proper scoring rules that can be evaluated, when only the probability of the most likely category is known. For example, we can use the score
<span class="math display">\[ cBS_\max:= p^2_{\max} - 2p_\max e_\max + 1.\]</span>
Note that this score satisfies
<span class="math inline">\(cBS_\max=BS_{\max} - e_\max +1\)</span>, so it’s a corrected version of the max-Brier score which is proper and avoids the problems above. Adding <span class="math inline">\(+1\)</span> in the definition of the score is not necessary but convenient: it ensures that the score is nonnegative and a perfect score is 0.</p>
<p>Usually we want to know whether our prediction outperformed climatology. For most scores we can consider skill scores, but unfortunately this does not work here. Climatology assigns to all three categories <em>equal</em> probabilities (1/3), and therefore does not really have a maximum-probability-category. Thus, the definition of <span class="math inline">\(e_\max\)</span> makes no sense for a climatological forecaster. However, a reasonable viewpoint is that for a climatological forecast the maximum-probability-category can be picked at random, since all categories are getting assigned the same probability.
This means that climatology achieves a score of 4/9 with probability 1/3 (when <span class="math inline">\(e_\max = 1\)</span>), but only achieves a score of 10/9 with probability 2/3. Thus, on average the climatological forecast achieves a score of <span class="math inline">\(\frac 1 3 \frac 4 9 + \frac 23 \frac {10}9 = \frac{24}{27}\)</span>. A forecast that attains a <span class="math inline">\(cBS_\max\)</span> of below 24/27 performs on average better than climatology. We therefore define the ‘skill score’
<span class="math display">\[cBSS_\max := 1 - \frac{27}{24}cBS_\max.\]</span>
Note that this is not a skill score in the strict sense, but can be interpretet similarly: values above 0 indicate higher skill than climatology on average, with a <span class="math inline">\(cBSS_\max\)</span> of 1 corresponding to a perfect forecast.</p>
<p>To try this out in action, let us look at the 2021 tercile forecasts</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="validation.html#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data_dir = &#39;/nr/project/stat/CONFER/Data/validation/example_data/202102/&#39; # as in section 3</span></span>
<span id="cb167-2"><a href="validation.html#cb167-2" aria-hidden="true" tabindex="-1"></a>fn <span class="ot">=</span> <span class="st">&#39;Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc&#39;</span></span>
<span id="cb167-3"><a href="validation.html#cb167-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-4"><a href="validation.html#cb167-4" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">=</span> <span class="fu">netcdf_to_dt</span>(<span class="fu">paste0</span>(data_dir,fn))</span></code></pre></div>
<pre><code>## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc (NC_FORMAT_CLASSIC):
## 
##      3 variables (excluding dimension variables):
##         float below[lon,lat]   
##             average_op_ncl: dim_avg_n over dimension(s): model
##             units: 
##             lead: 1
##             _FillValue: -9999
##         float normal[lon,lat]   
##             _FillValue: -9999
##             lead: 1
##             units: 
##             average_op_ncl: dim_avg_n over dimension(s): model
##         float above[lon,lat]   
##             _FillValue: -9999
##             lead: 1
##             units: 
##             average_op_ncl: dim_avg_n over dimension(s): model
## 
##      3 dimensions:
##         time  Size:0   *** is unlimited *** (no dimvar)
##         lat  Size:381 
##             units: degrees_north
##         lon  Size:326 
##             units: degrees_east
## 
##     7 global attributes:
##         creation_date: Thu Feb 18 17:06:05 EAT 2021
##         Conventions: None
##         source_file: Objective Forecast  
##         description:  Obtained by averaging CPT and local regression 
##         title: Tercile Consolidated Objective Forecast 
##         history: Mon Feb 22 10:28:53 2021: ncrename -v LAT,lat Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc
## Mon Feb 22 10:28:43 2021: ncrename -v LON,lon Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc
## Mon Feb 22 10:28:26 2021: ncrename -d LON,lon Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc
## Mon Feb 22 10:27:42 2021: ncrename -d LAT,lat Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc
##         NCO: netCDF Operators version 4.9.3 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco)</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="validation.html#cb169-1" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">=</span> dt[<span class="sc">!</span><span class="fu">is.na</span>(below) <span class="sc">|</span> <span class="sc">!</span><span class="fu">is.na</span>(normal) <span class="sc">|</span> <span class="sc">!</span><span class="fu">is.na</span> (above)]</span>
<span id="cb169-2"><a href="validation.html#cb169-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-3"><a href="validation.html#cb169-3" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt,<span class="at">data_col =</span> <span class="st">&#39;below&#39;</span>, <span class="at">midpoint =</span> dt[,<span class="fu">min</span>(below,<span class="at">na.rm =</span> <span class="cn">TRUE</span>)])</span>
<span id="cb169-4"><a href="validation.html#cb169-4" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt,<span class="at">data_col =</span> <span class="st">&#39;normal&#39;</span>, <span class="at">midpoint =</span> dt[,<span class="fu">min</span>(normal,<span class="at">na.rm =</span> <span class="cn">TRUE</span>)], <span class="at">high =</span> <span class="st">&#39;darkgoldenrod&#39;</span>) <span class="co"># see https://www.r-graph-gallery.com/ggplot2-color.html for an overview of color names.</span></span>
<span id="cb169-5"><a href="validation.html#cb169-5" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">=</span> <span class="fu">ggplot_dt</span>(dt,<span class="at">data_col =</span> <span class="st">&#39;above&#39;</span>, <span class="at">midpoint =</span> dt[,<span class="fu">min</span>(above,<span class="at">na.rm =</span> <span class="cn">TRUE</span>)], <span class="at">high =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb169-6"><a href="validation.html#cb169-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-7"><a href="validation.html#cb169-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggarrange</span>(p1,p2,p3,<span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Warning: Raster pixels are placed at uneven horizontal intervals and will be
## shifted. Consider using geom_tile() instead.</code></pre>
<pre><code>## Warning: Raster pixels are placed at uneven vertical intervals and will be
## shifted. Consider using geom_tile() instead.</code></pre>
<pre><code>## Warning: Raster pixels are placed at uneven horizontal intervals and will be
## shifted. Consider using geom_tile() instead.</code></pre>
<pre><code>## Warning: Raster pixels are placed at uneven vertical intervals and will be
## shifted. Consider using geom_tile() instead.</code></pre>
<pre><code>## Warning: Raster pixels are placed at uneven horizontal intervals and will be
## shifted. Consider using geom_tile() instead.</code></pre>
<pre><code>## Warning: Raster pixels are placed at uneven vertical intervals and will be
## shifted. Consider using geom_tile() instead.</code></pre>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-14-1.png" width="1152" /></p>
<p><em>In order to evaluate these forecast the high resolution CHIRPS-data of the past is missing!</em></p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="validation.html#cb176-1" aria-hidden="true" tabindex="-1"></a>fn <span class="ot">=</span> <span class="st">&quot;PredictedProbabilityRain_Mar-May_Feb2021_new.nc&quot;</span></span>
<span id="cb176-2"><a href="validation.html#cb176-2" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">=</span> <span class="fu">netcdf_to_dt</span>(<span class="fu">paste0</span>(data_dir,fn))</span></code></pre></div>
<pre><code>## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/PredictedProbabilityRain_Mar-May_Feb2021_new.nc (NC_FORMAT_NETCDF4):
## 
##      3 variables (excluding dimension variables):
##         float normal[lon,lat]   (Contiguous storage)  
##             _FillValue: -1
##         float above[lon,lat]   (Contiguous storage)  
##             _FillValue: -1
##             lead: 1
##             average_op_ncl: dim_avg_n over dimension(s): model
##             type: 2
##         float below[lon,lat]   (Contiguous storage)  
##             _FillValue: -1
##             lead: 1
##             average_op_ncl: dim_avg_n over dimension(s): model
##             type: 0
## 
##      2 dimensions:
##         lat  Size:77 
##             _FillValue: NaN
##             units: degrees_north
##         lon  Size:66 
##             _FillValue: NaN
##             units: degrees_east</code></pre>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="validation.html#cb178-1" aria-hidden="true" tabindex="-1"></a>dt[,normal <span class="sc">:</span><span class="er">=</span> normal<span class="sc">/</span><span class="dv">100</span>][,above <span class="sc">:</span><span class="er">=</span> above<span class="sc">/</span><span class="dv">100</span>][,below <span class="sc">:</span><span class="er">=</span> below<span class="sc">/</span><span class="dv">100</span>]</span></code></pre></div>
</div>
</div>
<div id="eval-ex-pr" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Exceedence probabilities</h2>
<p>Another forecast product issued at GHACOFs are exceedence probabilities of precipitation for certain thresholds, generally related to crops important for the region.
A proper scoring rule based on the predicted exceedence probability <span class="math inline">\(p_\text{exc}(c)\)</span> of a threshold <span class="math inline">\(c\)</span> is the Brier score of exceedence
<span class="math display">\[BS_{ex}(c) := (p_\text{exc}(c) - 1\{y&gt;c\})^2,\]</span>
where <span class="math inline">\(1\{y&gt;c\}\)</span> equals 1 if the observation <span class="math inline">\(y\)</span> exceeded threshold <span class="math inline">\(c\)</span>, and 0 else. Skill scores for comparison with a climatological forecast can be calculated in the usual way. The climatological forecast for the exceedence probability is the fraction of past observations that exceeded the threshold. In Section <a href="data-import-and-processing-1.html#data-ex-prexc">4.1.4</a> we already derived this dataset:</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="validation.html#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dt_prexc)</span></code></pre></div>
<pre><code>##          lon   lat month year rthr            model pexcd      clim       prec
##      1: 21.5 -12.0     2 2021  200         GEM-NEMO 0.996 0.3170732 213.685669
##      2: 21.5 -12.0     2 2021  200          CanCM4i 0.995 0.3170732 213.685669
##      3: 21.5 -12.0     2 2021  200     NASA-GEOSS2S 0.996 0.3170732 213.685669
##      4: 21.5 -12.0     2 2021  200       GFDL-SPEAR 0.990 0.3170732 213.685669
##      5: 21.5 -12.0     2 2021  200 COLA-RSMAS-CCSM4 0.993 0.3170732 213.685669
##     ---                                                                       
## 922316: 51.5  22.5     7 2021  400 COLA-RSMAS-CCSM4 0.000 0.0000000   9.597914
## 922317: 51.5  22.5     7 2021  400       NCEP-CFSv2 0.000 0.0000000   9.597914
## 922318: 51.5  22.5     7 2021  400            ECMWF    NA 0.0000000   9.597914
## 922319: 51.5  22.5     7 2021  400     Meteo_France    NA 0.0000000   9.597914
## 922320: 51.5  22.5     7 2021  400             UKMO    NA 0.0000000   9.597914</code></pre>
<p>This dataset contains predictions of exceedence (by different models) for several thresholds (rthr), as well as observed rainfall and a climatological prediction for the exceedence probabilities. This is everything we need to compute the <span class="math inline">\(BS_{ex}\)</span>-skill score. To this end, we have the function <code>BSS_ex_dt</code>. If we would not have a climatological exceedence forecast available, we could have still computed the <span class="math inline">\(BS_{ex}\)</span>-score using the function <code>BS_ex_dt</code>. This is still usefull for comparing competing models (see below), but does not tell us where the prediction is better or worse than climatology.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="validation.html#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="co"># bss_dt = BSS_ex_dt(dt_prexc,</span></span>
<span id="cb181-2"><a href="validation.html#cb181-2" aria-hidden="true" tabindex="-1"></a><span class="co">#                    f = &#39;pexcd&#39;,</span></span>
<span id="cb181-3"><a href="validation.html#cb181-3" aria-hidden="true" tabindex="-1"></a><span class="co">#                    threshold_col = &#39;rthr&#39;,</span></span>
<span id="cb181-4"><a href="validation.html#cb181-4" aria-hidden="true" tabindex="-1"></a><span class="co">#                    o = &#39;prec&#39;,</span></span>
<span id="cb181-5"><a href="validation.html#cb181-5" aria-hidden="true" tabindex="-1"></a><span class="co">#                    by = c(&#39;model&#39;,&#39;month&#39;,&#39;lon&#39;,&#39;lat&#39;))</span></span>
<span id="cb181-6"><a href="validation.html#cb181-6" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb181-7"><a href="validation.html#cb181-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print(bss_dt[!is.na(BS_ex)])</span></span></code></pre></div>
<p>Skill scores are generally not defined when the climatological prediction is perfect and the climatological score is zero. This happens frequently for exceedence probabilities (e.g. lines 3 and 4 in the data table above) at locations where the considered threshold has never been exceeded in the observation. Simply for plotting reasons we put the skill score to -1 in this case if the prediction scores above 0 (since the climatological prediction wwas better in this case), and to 0 if both climatology and prediction assign a probability of 0.
Let us look at the skill scores by the different models for the March forecast for exceedence level 200mm:</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="validation.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make a list of skill score plots:</span></span>
<span id="cb182-2"><a href="validation.html#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="co"># theme_set(theme_bw(base_size = 10)) # smaller font</span></span>
<span id="cb182-3"><a href="validation.html#cb182-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plot_list = list()</span></span>
<span id="cb182-4"><a href="validation.html#cb182-4" aria-hidden="true" tabindex="-1"></a><span class="co"># for(mod in unique(bss_dt[,model])) # 1 plot for each model</span></span>
<span id="cb182-5"><a href="validation.html#cb182-5" aria-hidden="true" tabindex="-1"></a><span class="co"># {</span></span>
<span id="cb182-6"><a href="validation.html#cb182-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   plot_list = c(plot_list,list(ggplot_dt( bss_dt[model == mod &amp; month == 3 &amp; rthr == 200],</span></span>
<span id="cb182-7"><a href="validation.html#cb182-7" aria-hidden="true" tabindex="-1"></a><span class="co">#                                           &#39;BSS_ex&#39;,</span></span>
<span id="cb182-8"><a href="validation.html#cb182-8" aria-hidden="true" tabindex="-1"></a><span class="co">#                                           mn = mod, </span></span>
<span id="cb182-9"><a href="validation.html#cb182-9" aria-hidden="true" tabindex="-1"></a><span class="co">#                                           high = &#39;red&#39;,</span></span>
<span id="cb182-10"><a href="validation.html#cb182-10" aria-hidden="true" tabindex="-1"></a><span class="co">#                                           midpoint = 0,</span></span>
<span id="cb182-11"><a href="validation.html#cb182-11" aria-hidden="true" tabindex="-1"></a><span class="co">#                                           rr= c(-1,1),</span></span>
<span id="cb182-12"><a href="validation.html#cb182-12" aria-hidden="true" tabindex="-1"></a><span class="co">#                                           guide = guide_colorbar(title = NULL, barwidth = 75, direction = &#39;horizontal&#39;))))</span></span>
<span id="cb182-13"><a href="validation.html#cb182-13" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb182-14"><a href="validation.html#cb182-14" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb182-15"><a href="validation.html#cb182-15" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb182-16"><a href="validation.html#cb182-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ggpubr::ggarrange(plotlist = plot_list,ncol = 3,nrow = 3,common.legend = TRUE,legend = &#39;bottom&#39;)</span></span></code></pre></div>
<p>Here, red color indicates better performance of the prediction than climatology. Large areas of the map are blue, which indicates better performance of the climatological forecast than of the prediction models. However, these are mostly areas where the observations never exceeded 200mm. Therefore, the climatological forecast issued a 0% chance of rainfall exceeding 200mm, whereas all actual prediction models issued a small positive probability and therefore performed ‘worse’. This not so much highlights a problem of the forecasts than rather a problem of skill scores, which become degenerate whenever the climatological prediction is near perfect.</p>
<p>For comparing overall performance, we can average scores spatially. Note that, because of the above-mentioned effect, it is important not to average skill scores. However, since we have a climatology forecast in our data table, we can compute a spatially averaged score for climatology as well. Thus, we can compare whether the prediction models performed on average better or worse than climatology.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="validation.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># mean_scores = bss_dt[,.(BS_ex = mean(BS_ex,na.rm = T)),by = .(model,month,rthr)]</span></span>
<span id="cb183-2"><a href="validation.html#cb183-2" aria-hidden="true" tabindex="-1"></a><span class="co"># # get climatology score as well:</span></span>
<span id="cb183-3"><a href="validation.html#cb183-3" aria-hidden="true" tabindex="-1"></a><span class="co"># mean_clim_score = bss_dt[model == model[1],.(BS_ex = mean(clim_BS_ex,na.rm = T)),by = .(month,rthr)]</span></span>
<span id="cb183-4"><a href="validation.html#cb183-4" aria-hidden="true" tabindex="-1"></a><span class="co"># mean_clim_score[,model := &#39;clim&#39;]</span></span>
<span id="cb183-5"><a href="validation.html#cb183-5" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb183-6"><a href="validation.html#cb183-6" aria-hidden="true" tabindex="-1"></a><span class="co"># mean_scores = rbindlist(list(mean_scores,mean_clim_score),use.names = TRUE)</span></span>
<span id="cb183-7"><a href="validation.html#cb183-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print(mean_scores)</span></span></code></pre></div>
<p>Here, every model gets assigned a single mean score for each month and each threshold (the mean score over all gridpoints). Lower values indicate better overall performance. Let us plot the data:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="validation.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pp = ggplot(mean_scores) + geom_line(aes(x = month,y = BS_ex,color = model,linetype = model)) + facet_wrap(~rthr,nrow = 1)</span></span>
<span id="cb184-2"><a href="validation.html#cb184-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb184-3"><a href="validation.html#cb184-3" aria-hidden="true" tabindex="-1"></a><span class="co">#print(pp)</span></span></code></pre></div>
<p>The plot shows that, averaging over all grid points, a climatological forecast does much better than all the systems, which probably indicates that the systems need to be bias corrected.</p>
</div>
<div id="temperature" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Temperature</h2>
<p>In our folder of example data we also have a file containing temperature predictions.
The file already contains correlations as well. Here we simply visualize these correlations as plots:</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="validation.html#cb185-1" aria-hidden="true" tabindex="-1"></a>fn <span class="ot">=</span> <span class="st">&#39;TrefEnsRegr_monthly.nc&#39;</span></span>
<span id="cb185-2"><a href="validation.html#cb185-2" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">=</span> <span class="fu">netcdf_to_dt</span>(<span class="fu">paste0</span>(data_dir,fn))</span></code></pre></div>
<pre><code>## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/TrefEnsRegr_monthly.nc (NC_FORMAT_CLASSIC):
## 
##      6 variables (excluding dimension variables):
##         float below[lon,lat,model,lead]   
##             units: %
##             _FillValue: -9999
##         float above[lon,lat,model,lead]   
##             units: %
##             _FillValue: -9999
##         float normal[lon,lat,model,lead]   
##             units: %
##             _FillValue: -9999
##         float corr[lon,lat,model,lead]   
##             units: cor
##             _FillValue: -9999
##         float tref[lon,lat,model,lead]   
##             units: K
##             _FillValue: -9999
##         float anom[lon,lat,model,lead]   
##             units: K
##             _FillValue: -9999
## 
##      4 dimensions:
##         lon  Size:66 
##             units: degreesE
##             long_name: lon
##         lat  Size:77 
##             units: degreesN
##             long_name: lat
##         model  Size:5 
##             units: number
##             long_name: model
##         lead  Size:3 
##             units: month
##             long_name: lead</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="validation.html#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot correlations of predictions for all five models at all lead_times:</span></span>
<span id="cb187-2"><a href="validation.html#cb187-2" aria-hidden="true" tabindex="-1"></a><span class="co"># create list of plots:</span></span>
<span id="cb187-3"><a href="validation.html#cb187-3" aria-hidden="true" tabindex="-1"></a>plot_list <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb187-4"><a href="validation.html#cb187-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(leadtime <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb187-5"><a href="validation.html#cb187-5" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb187-6"><a href="validation.html#cb187-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(mod <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb187-7"><a href="validation.html#cb187-7" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb187-8"><a href="validation.html#cb187-8" aria-hidden="true" tabindex="-1"></a>      plot_list <span class="ot">=</span> <span class="fu">c</span>(plot_list,<span class="fu">list</span>(<span class="fu">ggplot_dt</span>(dt[model <span class="sc">==</span> mod <span class="sc">&amp;</span> lead <span class="sc">==</span> leadtime],</span>
<span id="cb187-9"><a href="validation.html#cb187-9" aria-hidden="true" tabindex="-1"></a>                                        <span class="st">&#39;corr&#39;</span>,</span>
<span id="cb187-10"><a href="validation.html#cb187-10" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">rr =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb187-11"><a href="validation.html#cb187-11" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">mn =</span> <span class="fu">paste0</span>(<span class="st">&#39;model &#39;</span>,mod,<span class="st">&#39;, lead &#39;</span>,leadtime),</span>
<span id="cb187-12"><a href="validation.html#cb187-12" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">discrete_cs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb187-13"><a href="validation.html#cb187-13" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">binwidth =</span> <span class="fl">0.2</span>,</span>
<span id="cb187-14"><a href="validation.html#cb187-14" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">guide =</span> <span class="fu">guide_colorbar</span>(<span class="at">title =</span> <span class="cn">NULL</span>, </span>
<span id="cb187-15"><a href="validation.html#cb187-15" aria-hidden="true" tabindex="-1"></a>                                                               <span class="at">barwidth =</span> <span class="dv">75</span>,</span>
<span id="cb187-16"><a href="validation.html#cb187-16" aria-hidden="true" tabindex="-1"></a>                                                               <span class="at">direction =</span> <span class="st">&#39;horizontal&#39;</span>))))   }  </span>
<span id="cb187-17"><a href="validation.html#cb187-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb187-18"><a href="validation.html#cb187-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-19"><a href="validation.html#cb187-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-20"><a href="validation.html#cb187-20" aria-hidden="true" tabindex="-1"></a><span class="co">#plot as grid:</span></span>
<span id="cb187-21"><a href="validation.html#cb187-21" aria-hidden="true" tabindex="-1"></a><span class="fu">do.call</span>(<span class="st">&#39;ggarrange&#39;</span>, <span class="fu">c</span>(plot_list,<span class="at">ncol =</span> <span class="dv">5</span>,<span class="at">nrow =</span> <span class="dv">3</span>,<span class="at">common.legend =</span> <span class="cn">TRUE</span>,<span class="at">legend =</span> <span class="st">&#39;bottom&#39;</span>))</span></code></pre></div>
<p><img src="05-Seasonal_validation_files/figure-html/unnamed-chunk-21-1.png" width="960" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-import-and-processing-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="validation-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
