[["index.html", "Introduction", " The SeaVal package for validating seasonal weather forecasts Claudio Heinrich, Céline Cunen and Michael Scheuerer, with input from Masilin Gudoshava, Eunice Koech, Anthony Mwanthi, Zewdu Segele, Hussen Seid and Thordis Thorarinsdottir Introduction The R-package SeaVal provides functionality and many useful tools for evaluating seasonal forecasts. It is developed by the Norwegian Computing Center as part of the Horizon 2020 project CONFER. The goal of this project is to improve seasonal weather predictions in east Africa. Some functionality of this package is tailored to this purpose, specifically to evaluation practice and datasets at ICPAC, while other will be useful for evaluating seasonal predictions in general. Evaluating seasonal weather predictions requires an entire pipeline of tasks, including Importing the predictions Downloading and importing corresponding observations Matching predictions and observations, e.g. when they are on different grids Evaluating forecast skill Visualizing and exporting results The SeaVal package provides tools for all of these tasks. The development of this package is supported by the European Union’s Horizon 2020 research and innovation programme under grant agreement no. 869730 (CONFER). "],["getting-started.html", "1 Getting Started 1.1 Installation 1.2 examples of data.table syntax", " 1 Getting Started This tutorial shows how to get started with SeaVal and introduces its main functionality by examples. The package can be downloaded directly from github, see description below. SeaVal relies on R data tables (available with the R package data.table). Data tables are more flexible and memory efficient data frames, and simplify many operations that are frequently required when working with weather- and climate data. An introduction to data tables can be found here. 1.1 Installation In order to directly install the package from github, you need the package devtools. So if you have not installed it yet, you should first run install.packages(&#39;devtools&#39;) Thereafter, the SeaVal package including all dependencies can be installed by running the command devtools::install_github(&#39;SeasonalForecastingEngine/SeaVal&#39;) This may take a while, especially when some of the larger dependency packages are not installed, such as data.table or ggplot2. You may see a message like this: These packages have more recent versions available. It is recommended to update all of them. Which would you like to update? 1: All 2: CRAN packages only 3: None ... In that case type ‘1’ for all. (It is important to not only update CRAN packages: for technical reasons, the SeaVal package depends on a second package ForecastTools hosted on github, which is also developed by the Norwegian Computing Center) If this completes without an error, the setup is complete and you’re good to go. Now, all you have to do is load SeaVal: library(SeaVal) ## Loading required package: data.table ## Loading required package: ForecastTools ## Loading required package: ggplot2 ## Bioconductor version &#39;3.12&#39; is out-of-date; the current release version &#39;3.15&#39; ## is available with R version &#39;4.2&#39;; see https://bioconductor.org/install The rest of the tutorial is organized as follows. We will first give a few examples how to use Rs data table syntax to perform typical tasks required for evaluation. Thereafter, we will show how SeaVal can be used to visualize data as spatial maps. This will be followed by examples how to import forecasts and download observations data. Thereafter, the tutorial shows how observations and predictions can be combined into a suitable dataset for evaluation. Finally, it shows how to evaluate different types of forecasts 1.2 examples of data.table syntax Here, we show some examples of basic operations on data tables. A short but comprehensive introduction to data.tables syntax can be found here. The SeaVal package comes with a few example data sets we will use here, for example monthly mean precipitation over the GHA region for the OND season provided by CHIRPS: data(&quot;chirps_monthly&quot;) print(chirps_monthly) ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 1.9301587 10 1981 -1 ## 2: 22.0 -11.5 2.1351602 10 1981 -1 ## 3: 22.0 -11.0 2.7692883 10 1981 -1 ## 4: 22.0 -10.5 3.9201619 10 1981 0 ## 5: 22.0 -10.0 4.8720656 10 1981 1 ## --- ## 418076: 51.5 21.0 0.2404348 12 2020 -1 ## 418077: 51.5 21.5 0.2184058 12 2020 -1 ## 418078: 51.5 22.0 0.2053623 12 2020 -1 ## 418079: 51.5 22.5 0.1615942 12 2020 -1 ## 418080: 51.5 23.0 0.1387682 12 2020 -1 A short description of the dataset is also provided: ?chirps_monthly We’ll now go over a few basic commands for handling this sort of data. chirps_monthly is a data table, which is an enhanced data frame. The most fundamental operations include subsetting, performing calculations on columns and aggregation or grouping for calculations. Examples for subsetting are chirps_monthly[month == 10] # extract the data for October ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 1.930158724 10 1981 -1 ## 2: 22.0 -11.5 2.135160243 10 1981 -1 ## 3: 22.0 -11.0 2.769288266 10 1981 -1 ## 4: 22.0 -10.5 3.920161870 10 1981 0 ## 5: 22.0 -10.0 4.872065602 10 1981 1 ## --- ## 139356: 51.5 21.0 0.033333333 10 2020 -1 ## 139357: 51.5 21.5 0.033333333 10 2020 0 ## 139358: 51.5 22.0 0.032608688 10 2020 -1 ## 139359: 51.5 22.5 0.001594238 10 2020 -1 ## 139360: 51.5 23.0 0.000000000 10 2020 -1 chirps_monthly[year %between% c(1990,1999)] # extract the data for 1990 - 1999 ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 3.1261905 10 1990 1 ## 2: 22.0 -11.5 3.5520651 10 1990 1 ## 3: 22.0 -11.0 3.9256340 10 1990 1 ## 4: 22.0 -10.5 4.4879379 10 1990 1 ## 5: 22.0 -10.0 4.4143639 10 1990 0 ## --- ## 104516: 51.5 21.0 0.2565218 12 1999 0 ## 104517: 51.5 21.5 0.2427537 12 1999 1 ## 104518: 51.5 22.0 0.2171015 12 1999 1 ## 104519: 51.5 22.5 0.2000000 12 1999 1 ## 104520: 51.5 23.0 0.1981884 12 1999 1 chirps_monthly[1000:2000] # extract rows 1000 - 2000 ## lon lat prec month year terc_cat ## 1: 29 -9.5 1.74899961 10 1981 0 ## 2: 29 -9.0 1.44546648 10 1981 -1 ## 3: 29 -8.5 1.45933371 10 1981 -1 ## 4: 29 -8.0 1.52153314 10 1981 -1 ## 5: 29 -7.5 1.35046587 10 1981 -1 ## --- ## 997: 36 -8.5 0.49439943 10 1981 0 ## 998: 36 -8.0 0.31293185 10 1981 0 ## 999: 36 -7.5 0.06879925 10 1981 -1 ## 1000: 36 -7.0 0.01446661 10 1981 -1 ## 1001: 36 -6.5 0.04019988 10 1981 0 chirps_monthly[month == 10][lon &gt; 30][terc_cat == 0] #chained subsetting: get all October values at locations with longitude &gt;30 that had normal rainfall (terc_cat == 0) ## lon lat prec month year terc_cat ## 1: 30.5 -10.5 0.67720063 10 1981 0 ## 2: 30.5 -10.0 0.78526832 10 1981 0 ## 3: 30.5 -9.5 1.03640187 10 1981 0 ## 4: 30.5 -9.0 0.96939957 10 1981 0 ## 5: 30.5 -8.5 0.52219994 10 1981 0 ## --- ## 32909: 51.0 20.0 0.06666667 10 2020 0 ## 32910: 51.0 21.5 0.03333333 10 2020 0 ## 32911: 51.5 19.5 0.06666667 10 2020 0 ## 32912: 51.5 20.0 0.06666667 10 2020 0 ## 32913: 51.5 21.5 0.03333333 10 2020 0 chirps_monthly[month == 10 &amp; lon &gt; 30 &amp; terc_cat == 0] # different syntax, same effect. ## lon lat prec month year terc_cat ## 1: 30.5 -10.5 0.67720063 10 1981 0 ## 2: 30.5 -10.0 0.78526832 10 1981 0 ## 3: 30.5 -9.5 1.03640187 10 1981 0 ## 4: 30.5 -9.0 0.96939957 10 1981 0 ## 5: 30.5 -8.5 0.52219994 10 1981 0 ## --- ## 32909: 51.0 20.0 0.06666667 10 2020 0 ## 32910: 51.0 21.5 0.03333333 10 2020 0 ## 32911: 51.5 19.5 0.06666667 10 2020 0 ## 32912: 51.5 20.0 0.06666667 10 2020 0 ## 32913: 51.5 21.5 0.03333333 10 2020 0 We can subset either by logical expressions (first two examples) or by row indices (third example). Subsetting always returns a data table, e.g. chirps_monthly[1] returns a one-row data table containing the first row of chirps_monthly. Next, let’s look at examples for operations on columns: chirps_monthly[,mean(prec)] # get the mean precipitation (over all locations, months, years) ## [1] 1.995215 chirps_monthly[,mean_prec := mean(prec)] # create a new column in the data table containing the mean chirps_monthly[,prec := 30*prec] # transform precipitation from unit mm/day to mm (per month) print(chirps_monthly) ## lon lat prec month year terc_cat mean_prec ## 1: 22.0 -12.0 57.904762 10 1981 -1 1.995215 ## 2: 22.0 -11.5 64.054807 10 1981 -1 1.995215 ## 3: 22.0 -11.0 83.078648 10 1981 -1 1.995215 ## 4: 22.0 -10.5 117.604856 10 1981 0 1.995215 ## 5: 22.0 -10.0 146.161968 10 1981 1 1.995215 ## --- ## 418076: 51.5 21.0 7.213044 12 2020 -1 1.995215 ## 418077: 51.5 21.5 6.552173 12 2020 -1 1.995215 ## 418078: 51.5 22.0 6.160868 12 2020 -1 1.995215 ## 418079: 51.5 22.5 4.847827 12 2020 -1 1.995215 ## 418080: 51.5 23.0 4.163046 12 2020 -1 1.995215 Note in all cases the ‘,’ after ‘[’ which tells data table that you’re doing an operation rather than trying to subset. We can also put things together and subset and operate simultaneously. In this case the subsetting is specified first, followed by a comma followed by the operation: chirps_monthly[month == 10 , mean(prec)] # get the mean precipitation for October (over all locations, years) ## [1] 66.30285 (Note that the mean is much larger now because we changed units…). Finally, and most importantly, we can perform operations over aggregated groups: dt_new = chirps_monthly[, mean(prec),by = .(lon,lat,month)] print(dt_new) ## lon lat month V1 ## 1: 22.0 -12.0 10 84.507765 ## 2: 22.0 -11.5 10 92.716755 ## 3: 22.0 -11.0 10 104.027108 ## 4: 22.0 -10.5 10 116.425850 ## 5: 22.0 -10.0 10 128.969907 ## --- ## 10448: 51.5 21.0 12 7.679457 ## 10449: 51.5 21.5 12 7.247609 ## 10450: 51.5 22.0 12 6.454131 ## 10451: 51.5 22.5 12 5.612391 ## 10452: 51.5 23.0 12 5.103941 Here, the ‘by’ command (after the second comma) tells data table to perform the operation (mean) for each unique instance of lon, lat, and month separately. As a result, the mean is taken only over all years, and a separate mean is derived for each location and each month. Therefore, this operation derives the monthly local climatology. As we can see, the output is a data table containing all columns in by and a column named V1 containing the output of the operation. That’s a bit impractical, so let’s rename the last column: setnames(dt_new,&#39;V1&#39;,&#39;clim&#39;) # take the data table from above and rename column &#39;V1&#39; into &#39;clim&#39; It’s also possible to name the column direcly while dt_new is created, like this: dt_new = chirps_monthly[,.(clim = mean(prec)),by = .(lon,lat,month)] # same as above, but with simultaneously setting the name of the new column This can again be combined with subsetting: dt_new = chirps_monthly[year %in% 1990:2020, .(clim = mean(prec)), by = .(lon,lat,month)] # computes climatology based on the years 1990-2020 only. In the examples above we create a new data table containing the climatology. If we instead want to add the climatology as a new column to chirps_monthly directly, we need to use the := operator: chirps_monthly[,clim := mean(prec), by = .(lon,lat,month)] # add the climatology column directly into chirps_monthly. This showcases some of the functionalities and syntax of the data.table package. There’s a lot more to it and we recommend having a look at this introduction to data.table if you are not familiar with data tables. In particular, this introduction explains the logic behind the syntax making it much easier to memorize. We’ll finish this section by an example where we compute the MSE for raw ecmwf forecasts: data(&quot;chirps_monthly&quot;) # reload data to reverse the changes made in the examples above. data(&quot;ecmwf_monthly&quot;) # get example hindcasts from ecmwf print(ecmwf_monthly) ## lon lat year month prec member below normal above ## 1: 22 13.0 1993 10 0.0118023199 1 0.60 0.20 0.20 ## 2: 22 13.0 1993 10 0.0257743523 2 0.60 0.20 0.20 ## 3: 22 13.0 1993 10 0.0008075972 3 0.60 0.20 0.20 ## 4: 22 13.0 1993 10 0.1190863216 4 0.60 0.20 0.20 ## 5: 22 13.0 1993 10 0.0002728474 5 0.60 0.20 0.20 ## --- ## 868556: 51 11.5 2020 12 0.8410410288 1 0.36 0.28 0.36 ## 868557: 51 11.5 2020 12 0.7719732821 2 0.36 0.28 0.36 ## 868558: 51 11.5 2020 12 1.4691380784 3 0.36 0.28 0.36 ## 868559: 51 11.5 2020 12 1.2364573109 4 0.36 0.28 0.36 ## 868560: 51 11.5 2020 12 1.2289135981 5 0.36 0.28 0.36 # merge observations and predictions into a single data table: setnames(chirps_monthly,&#39;prec&#39;,&#39;obs&#39;) # rename the &#39;prec&#39; column in the observation data table to &#39;obs&#39;, # in order to avoid name clashes, since ecmwf_monthly also contains a column &#39;prec&#39;, # containing the predictions for precip. dt = merge(ecmwf_monthly,chirps_monthly, by = c(&#39;lon&#39;,&#39;lat&#39;,&#39;year&#39;,&#39;month&#39;)) # merge hindcasts and observations into one data table. print(dt) ## lon lat year month prec member below normal above obs ## 1: 22 13.0 1993 10 0.0118023199 1 0.60 0.20 0.20 0.3490475 ## 2: 22 13.0 1993 10 0.0257743523 2 0.60 0.20 0.20 0.3490475 ## 3: 22 13.0 1993 10 0.0008075972 3 0.60 0.20 0.20 0.3490475 ## 4: 22 13.0 1993 10 0.1190863216 4 0.60 0.20 0.20 0.3490475 ## 5: 22 13.0 1993 10 0.0002728474 5 0.60 0.20 0.20 0.3490475 ## --- ## 868556: 51 11.5 2020 12 0.8410410288 1 0.36 0.28 0.36 0.5262209 ## 868557: 51 11.5 2020 12 0.7719732821 2 0.36 0.28 0.36 0.5262209 ## 868558: 51 11.5 2020 12 1.4691380784 3 0.36 0.28 0.36 0.5262209 ## 868559: 51 11.5 2020 12 1.2364573109 4 0.36 0.28 0.36 0.5262209 ## 868560: 51 11.5 2020 12 1.2289135981 5 0.36 0.28 0.36 0.5262209 ## terc_cat ## 1: 0 ## 2: 0 ## 3: 0 ## 4: 0 ## 5: 0 ## --- ## 868556: 0 ## 868557: 0 ## 868558: 0 ## 868559: 0 ## 868560: 0 dt[,ens_mean := mean(prec),by = .(lon,lat,year,month)] # get the ensemble mean as a new column. # The mean is here grouped over all dimension variables excluding &#39;member&#39;, # therefore the ensemble mean is returned. In other words, a separate mean # is calculated for every instance of lon, lat, year and month. mse_dt = dt[,.(mse = mean((prec-obs)^2)), by = .(lon,lat,month)] # create a new data.table containing the mse by location and month print(mse_dt) ## lon lat month mse ## 1: 22.0 13.0 10 7.263275e-01 ## 2: 22.0 13.0 11 2.330523e-03 ## 3: 22.0 13.0 12 4.717186e-05 ## 4: 22.5 12.5 10 1.100971e+00 ## 5: 22.5 12.5 11 8.114504e-03 ## --- ## 6200: 51.0 11.0 11 2.520367e+00 ## 6201: 51.0 11.0 12 1.086045e+00 ## 6202: 51.0 11.5 10 1.304131e+00 ## 6203: 51.0 11.5 11 3.431530e+00 ## 6204: 51.0 11.5 12 1.362873e+00 # plot mse for October: ggplot_dt(mse_dt[month == 10],&#39;mse&#39;,rr = c(-10,10) ) The function ggplot_dt is used to create spatial plots from data stored in data tables. The next section highlights how to use this function and how the generated plots can be manipulated. "],["plotting.html", "2 Plotting 2.1 Plotting values for selected countries 2.2 Customized plots", " 2 Plotting The function ggplot_dt takes a data table containing two columns named lon and lat that should specify a regular longitude-latitude grid, as well as some data to use for coloring the map. The naming of the columns is important in that the function will not work if you, for example, name the longitude column long or Lon. An easy example is the following data(&quot;chirps_monthly&quot;) dt = copy(chirps_monthly) # to manipulate the data table: chirps_monthly has locked binding dt2020 = dt[year == 2020 &amp; month == 10] # reduce the observed precipitation data to a single time slice, namely October 2020 # our data now looks like this: print(dt2020) ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 2.981750252 10 2020 0 ## 2: 22.0 -11.5 3.382063644 10 2020 0 ## 3: 22.0 -11.0 3.250394658 10 2020 0 ## 4: 22.0 -10.5 3.065396443 10 2020 -1 ## 5: 22.0 -10.0 3.416906726 10 2020 -1 ## --- ## 3480: 51.5 21.0 0.033333333 10 2020 -1 ## 3481: 51.5 21.5 0.033333333 10 2020 0 ## 3482: 51.5 22.0 0.032608688 10 2020 -1 ## 3483: 51.5 22.5 0.001594238 10 2020 -1 ## 3484: 51.5 23.0 0.000000000 10 2020 -1 ggplot_dt(dt2020,&#39;prec&#39;) # we pass the data table and the name of the column containing the plotting data, As we can see, the color scale here makes no sense (blue meaning no precipitation) and we’ll talk about that in a second. But let’s start at the base functionality. ggplot_dt requires two arguments, the first one being a data table containing the data, and the second one is the name of the column that contains the data you want to plot. This defaults to the third column in the data table (often your data table will start with lon, lat, and the third column is what you want to plot). So in the example above, ggplot_dt(dt) would have led to the same result, because 'prec' is the third column in dt. The plotting window is determined by the data. If you have data covering the entire earth, the entire earth would be plotted. As a consequence, we can restrict the plotted region by subsetting the data table: dt_sub = dt2020[lon %between% c(28,43) &amp; lat %between% c(-12,1)] # a region containing Tanzania ggplot_dt(dt_sub) The function has further optional arguments (also recall that you can access the function documentation summarizing all of this by typing ?ggplot_dt): ggplot_dt(dt_sub,&#39;prec&#39;, mn = &#39;October 2020 precipitation&#39;, # add a title to the plot rr = c(1,10), # fix the limits of the color scale name = &#39;mm/day&#39;) # change the legend label In this example we set the lower limit of the color scale to 1 and the upper limit to 10. By default the data is truncated at the ends of the color scale, so every pixel with precipitation of below 1mm/day is now shown in the same blue color, the color corresponding to a value of 1 mm. Setting the range of the color scale is useful for making several plots comparable or to force symmetry around 0, e.g. when plotting correlations or anomalies: dt[,clim := mean(prec), by = .(lon,lat,month)] # add a climatology column to dt dt[,ano := prec - clim] # add an anomaly column to dt print(dt) ## lon lat prec month year terc_cat clim ano ## 1: 22.0 -12.0 1.9301587 10 1981 -1 2.8169255 -0.886766778 ## 2: 22.0 -11.5 2.1351602 10 1981 -1 3.0905585 -0.955398264 ## 3: 22.0 -11.0 2.7692883 10 1981 -1 3.4675703 -0.698281996 ## 4: 22.0 -10.5 3.9201619 10 1981 0 3.8808617 0.039300191 ## 5: 22.0 -10.0 4.8720656 10 1981 1 4.2989969 0.573068714 ## --- ## 418076: 51.5 21.0 0.2404348 12 2020 -1 0.2559819 -0.015547112 ## 418077: 51.5 21.5 0.2184058 12 2020 -1 0.2415870 -0.023181188 ## 418078: 51.5 22.0 0.2053623 12 2020 -1 0.2151377 -0.009775418 ## 418079: 51.5 22.5 0.1615942 12 2020 -1 0.1870797 -0.025485473 ## 418080: 51.5 23.0 0.1387682 12 2020 -1 0.1701314 -0.031363167 ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, rr = c(-3,3)) Now, in this plot positive rainfall anomalies are shown red while negative anomalies are blue, which is very unintuitive. The function allows us to specify the three used colors by name with the arguments low,mid, and high. An overview over available color names can be found here. So here’s an anomaly plot looking a bit nicer: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, rr = c(-3,3), low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, name = &#39;mm/day&#39;) Note that we set the range argument to c(-3,3). Fixing the range mostly makes sense when the range is known (e.g. for correlation plots), or when you want to compare several plots (e.g. for comparing mean square error of different NWP models, all plots should have the same range). If we leave the range argument rr free, the range is determined from the data. However, when we do this for our anomaly plot this has an undesired sideeffect: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, name = &#39;mm/day&#39;) The color scale is no longer centered (white) at 0, but in the center of the (now asymetric) range. As a consequence, all gridpoints with anomaly 0 are shown in a light red. To fix this, we can use the midpoint argument: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) Another, maybe surprising, use for the midpoint argument is that we can generate plots with a colorscale with only two colors. For example, going back to plotting the observed rainfall we can do the following: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;prec&#39;, mn = &#39;October 2020 rainfall&#39;, mid = &#39;white&#39;, high = &#39;blue&#39;, midpoint = 0, name = &#39;mm/day&#39;) Here, we set the midpoint to 0, which is the minimum of our data (since observed rainfall is never below 0). Consequently, the second half of the colorscale extending below 0 is ignored. Finally, the function allows to discretize the color scale. To this end the argument discrete_cs should be set to TRUE. We can then control the breaks of the discrete colorscale by one of the arguments binwidth, n.breaks, or breaks (the latter takes a vector containing all breakpoints). Using binwidth is recommended: The argument n.breaks (which is passed to the function ggplot2::scale_fill_steps2) tries to find ‘nice’ breaks and does not work reliably, and breaks is often a bit tedious. To revisit the anomaly plot from above: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) For saving a created plot, we can use any of Rs graphical devices, e.g. pdf(file = &#39;&lt;path to file and filename&gt;.pdf&#39;, width = ...,height = ...) print(pp) dev.off() This creates a .pdf file, but you can print .png and some other file formats similarly, see ?Devices for an overview. One final remark: Often you will deal with data tables that contain spatio-temporal data. It is then important to remember subselecting the particular timeslice you want to view, (October 2020 in the examples above). The function ggplot_dt by default tries to select the first timeslice of tempo-spatial data. This is convenient for a quick first look at your data. Here an example: print(chirps_monthly) # a data table with multiple months and years and locations, so spatio-temporal data ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 1.9301587 10 1981 -1 ## 2: 22.0 -11.5 2.1351602 10 1981 -1 ## 3: 22.0 -11.0 2.7692883 10 1981 -1 ## 4: 22.0 -10.5 3.9201619 10 1981 0 ## 5: 22.0 -10.0 4.8720656 10 1981 1 ## --- ## 418076: 51.5 21.0 0.2404348 12 2020 -1 ## 418077: 51.5 21.5 0.2184058 12 2020 -1 ## 418078: 51.5 22.0 0.2053623 12 2020 -1 ## 418079: 51.5 22.5 0.1615942 12 2020 -1 ## 418080: 51.5 23.0 0.1387682 12 2020 -1 ggplot_dt(chirps_monthly) # generates a plot of the precipitation of October 1981 (first timeslice), for a first quick impression of your data. 2.1 Plotting values for selected countries Above, we have already seen an option how to restrict a plot to a particular country: by manually subsetting the data to a rectangle of longitudes and latitudes containing that specific country. This is of course quite tedious, and to make our lives easier we can use the restrict_to_country-function that takes a data table and a country name, and subsets the data table to only contain gridpoints in the specified country. Currently, the function accepts the following country names: Burundi, Eritrea, Ethiopia, Kenya, Rwanda, Somalia, South Sudan, Sudan, Tanzania, Uganda. dt_new = restrict_to_country(dt[month == 10 &amp; year == 2020],&#39;Kenya&#39;) print(dt_new) ## lon lat prec month year terc_cat clim ano ## 1: 34.0 -1.0 4.9593979 10 2020 1 2.964475 1.9949232 ## 2: 34.0 -0.5 4.7645891 10 2020 1 3.639693 1.1248956 ## 3: 34.0 0.0 4.6154697 10 2020 1 4.284345 0.3311242 ## 4: 34.5 -1.0 7.5550100 10 2020 1 4.380272 3.1747380 ## 5: 34.5 -0.5 6.4341863 10 2020 1 4.056996 2.3771907 ## --- ## 187: 41.0 -1.0 0.7533339 10 2020 -1 2.456691 -1.7033568 ## 188: 41.0 3.0 1.1354665 10 2020 0 2.135546 -1.0000791 ## 189: 41.0 3.5 1.5012010 10 2020 0 2.191273 -0.6900723 ## 190: 41.0 4.0 1.8609376 10 2020 0 2.431412 -0.5704748 ## 191: 41.5 3.5 1.3543324 10 2020 0 2.447758 -1.0934261 ggplot_dt(dt_new, &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) As we can see, the function restricts the data to all gridcells for which the centerpoint lies within the specified country. This is useful, for example, for calculating mean scores for the specified country. However, it is not optimal for plotting, since all grid cells past the border are censored, even though the original data table contained values there. To this end, the restrict_to_country function has a rectangle-argument that you can set to TRUE for plotting: dt_new = restrict_to_country(dt[month == 10 &amp; year == 2020],&#39;Kenya&#39;, rectangle = TRUE) ggplot_dt(dt_new, &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) Instead of a single country name, you can also pass multiple country names in a vector to the function. Moreover, when you use rectangle = TRUE, you can specify a tolerance tol in order to widen the plotting window: dt_new = restrict_to_country(dt[month == 10 &amp; year == 2020], c(&#39;Kenya&#39;,&#39;Tanzania&#39;), rectangle = TRUE,tol = 2) ggplot_dt(dt_new, &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) The tol = 2 argument means that the function will include a buffer zone of 2 degrees lon/lat outside the specified countries (i.e. 4 gridpoints to each side). Note that the buffer to the south of Tanzania is smaller, because the original data table dt does not contain any data further south. 2.2 Customized plots The function ggplot_dt is, as its name suggests, based on the package ggplot2. This is a widely-used package and there are many books and tutorials available for getting familiar with the syntax, e.g. (this one)[https://ggplot2-book.org/]. In ggplot2, plots are composed out of multiple layers, allowing for successive adding of layers. This can help us to generate highly customized plots. As an example, let’s revisit the anomaly plot from above and add the location of Nairobi an Addis Abbaba to it: library(ggplot2) # get locations as data table: loc = data.table(name = c(&#39;Addis Abbaba&#39;,&#39;Nairobi&#39;),lon = c(38.77,36.84),lat = c(9,-1.28)) print(loc) ## name lon lat ## 1: Addis Abbaba 38.77 9.00 ## 2: Nairobi 36.84 -1.28 pp = ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) + geom_point(data = loc,mapping = aes(x = lon,y = lat)) + geom_text(data = loc,mapping = aes(x = lon,y = lat,label = name),vjust = 1.5) print(pp) Here, we added two layers to the original plot, the first one being the geom_point-layer that creates the two points at the locations of the cities, and the second being the geom_text-layer that labels the points by the city names. A frequently required operation is the changing of the font sizes of title and labels. The easiest way to do this is the command theme_set(theme_bw(base_size = 16)) # defaults to 12 print(pp) We can also use ggplots adding-layer-syntax to overwrite existing layers, for example if we want a fully customized colorscale: library(viridis) # the viridis package contains some nice color scales pp_new = pp + scale_fill_viridis(name = &#39;my_color_scale&#39;, breaks = seq(-5,5,by = 2), guide = guide_colorbar(title = &#39;my personal color scale&#39;, title.position = &#39;top&#39;, barwidth = 20, direction = &#39;horizontal&#39;)) + xlab(&#39;lon&#39;) + ylab(&#39;lat&#39;) + # label axis theme(panel.background = element_rect(fill = &#39;salmon&#39;), # change background color (used for missing values) to something whackey axis.ticks = element_line(), # add ticks... axis.text = element_text(), # ... and labels for the axis, i.e. some lons and lats. legend.position = &#39;bottom&#39;) print(pp_new) For comparing multiple plots (potentially all of them with the same legend), the function ggpubr::ggarrange is useful: library(ggpubr) # compare 2019 October anomaly to 2020 anomaly: rr = c(-5,5) # force color scale to be identical for the plots pp1 = ggplot_dt(dt[month == 10 &amp; year == 2019], &#39;ano&#39;, rr = rr, mn = &#39;October 2019 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, guide = guide_colorbar(barwidth = 20,barheight = 1,direction = &#39;horizontal&#39;), midpoint = 0, name = &#39;mm/day&#39;) + geom_point(data = loc,mapping = aes(x = lon,y = lat)) + geom_text(data = loc,mapping = aes(x = lon,y = lat,label = name),vjust = 1.5) pp2 = ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, rr = rr, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) + geom_point(data = loc,mapping = aes(x = lon,y = lat)) + geom_text(data = loc,mapping = aes(x = lon,y = lat,label = name),vjust = 1.5) ggarrange(pp1,pp2,ncol = 2,common.legend = TRUE,legend = &#39;bottom&#39;) "],["data-import-and-processing.html", "3 Data import and processing 3.1 The function netcdf_to_dt 3.2 Downloading and processing CHIRPS data", " 3 Data import and processing The SeaVal package provides some tools for data import and export (currently limited to netcdf files). Moreover, evaluation always requires comparison to observations, and the package downloads and organizes monthly means CHIRPS data. Note that, for seasonal forecasts, observations are frequently considered relative to the local climatology: For example, high rainfall is frequently defined as more rainfall than in 2/3 of all other years (at the samme location and time of year). This requires the download of more observations than just for the year you want to evaluate (because you need to establish what is normal for the considered region/season). 3.1 The function netcdf_to_dt The central function for importing netcdf-data as data.table is called netcdf_to_dt. It takes a filename of a netcdf (including directory path) as argument. The example files we consider are hosted on ICPACs ftp server at SharedData/gcm/seasonal/202102. print(data_dir) # the directory the data is stored in, you need to adjust this to your platform. ## [1] &quot;/nr/project/stat/CONFER/Data/SeaVal/example_data/202102/&quot; fn = &quot;CorrelationSkillRain_Feb-Apr_Feb2021.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/CorrelationSkillRain_Feb-Apr_Feb2021.nc (NC_FORMAT_CLASSIC): ## ## 1 variables (excluding dimension variables): ## float corr[lon,lat] ## lead: 0 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 0 ## time: 13 ## _FillValue: -9999 ## ## 3 dimensions: ## time Size:0 *** is unlimited *** (no dimvar) ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ## 6 global attributes: ## units: mm ## MonInit_month: 2 ## valid_time: Feb-Apr ## creation_date: Mon Feb 15 06:59:57 EAT 2021 ## Conventions: None ## title: Correlation between Cross-Validated and Observed Rainfall print(dt) ## lon lat corr ## 1: 20.5 -13.5 NA ## 2: 21.0 -13.5 NA ## 3: 21.5 -13.5 NA ## 4: 22.0 -13.5 NA ## 5: 22.5 -13.5 NA ## --- ## 5078: 51.0 24.5 NA ## 5079: 51.5 24.5 NA ## 5080: 52.0 24.5 NA ## 5081: 52.5 24.5 NA ## 5082: 53.0 24.5 NA By default, the function prints out all the information it gets from the netcdf, including units, array sizes etc. This can be turned off by the verbose argument of the function: setting it to 0 supresses all messages, setting it to 1 only prints units of the variables. The default value is 2. A netcdf file always contains variables (such as precip or temperature) and dimension variables (such as longitude or time). The function netcdf_to_dt by default tries to extract all variables into a single data table that also contains all dimension variables that are indexing at least one variable: For example, the netcdf file above has three dimension variables: lon,lat, and time (which is empty). It has one variable (‘corr’) that is indexed by lon and lat, therefore the resulting data table has three columns: corr, lon and lat. The default behavior of merging all netcdf data into a single data table may sometimes be inappropriate. Say, for example, we have a netcdf with three dimension variables lon,lat and time, and it has a variable precipitation[lon,lat,time] and a second variable grid_point_index[lon,lat]. The resulting data table would have the columns lon,lat,time,precipitation, and grid_point_index. This is not very memory efficient because the grid_point_indices are repeated for every instance of time. Moreover, in this case we probably don’t need the grid_point_index anyway. We can use the vars argument of the netcdf_to_dt function to extract only selected variables. So, in this example, netcdf_to_dt('example_file.nc', vars = 'precipitation') would have done the trick. Merging the data tables for all variables is particularly memory efficient when you have multiple variables that have different dimension variables. For large netcdfs with many variables and many dimension variables this can easily get out of hand. In this case you can use netcdf_to_dt('example_file.nc',trymerge = FALSE). This will return a list of data tables, one data table for each variable, containing only the variable values and the dimension variables it is indexed by. If you have two or more variables that do not share a dimension variable, the function requires you to set trymerge = FALSE, see the example in Section 4.0.3. For the example above, the resulting data table looks like this: ggplot_dt(dt, mn = &#39;Corr. skill rain Feb-Apr, Feb initialized&#39;, # title rr = c(-1,1), # range of the colorbar discrete_cs = TRUE,binwidth = 0.4) # discretize colorbar Note that the area shown by ggplot_dt is always the full extend of the data contained in the data table. In particular, the correlation plot above extends beyond areas where we have data, because the netcdf-file contained these locations (with missing values in the ‘corr’-array). To just plot a window taylored to the data that is not missing, we can simply suppress the missing values by using dt[!is.na(corr)]. We can compare to the February initialized forecast for March to May: fn = &quot;CorrelationSkillRain_Mar-May_Feb2021.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn),verbose = 0) ggplot_dt(dt[!is.na(corr)], # here we suppress missing values mn = &#39;Corr. skill rain Mar-May, Mar initialized&#39;, # title rr = c(-1,1), # range of the colorbar discrete_cs = TRUE,binwidth = 0.4) # discretize colorbar Similarly, for writing netcdf files from data tables, the package has a function dt_to_netcdf. The function requires a data table as input as well as the names of the columns containing the variables and dimension variables, and a filename to write to. The function will prompt you for units for all variables, but otherwise does not allow to include detailed descriptions in the netcdf. It also currently does not support writing netcdfs with multiple variables that have different dimension variables. You can use the Rpackage ncdf4 for that. 3.2 Downloading and processing CHIRPS data Evaluation of forecasts always requires observations to assess the forecast performance. Moreover, usually we are interested whether the prediction was as good or better than a naive climatological forecast. This requires establishing a climatology which requires access to past observations as well. To this end, the SeaVal package provides code that simplifies the download and use of the CHIRPS monthly means rainfall data set. The CHIRPS data is created by the Climate Hazard Group of UC Santa Barbara. The data is mirrored on the IRI data library, which allows downloading (area-)subsetted data. In order to download all available CHIRPS monthly mean data to your local machine, it is sufficient to run the function download_chirps_monthly() The first time you run this function, it will ask you to specify a data directory on your local machine. This path is saved and from now on generally used by the SeaVal package for storing and loading data. You can later look up which data directory you specified by running data_dir(). In theory you should not change your data directory. If, for some reason, you have to you can run data_dir(set_dir = TRUE). However, this simply generates a new empty data directory and specifies the new directory as lookup path for the SeaVal package. It does not move over or delete data in the old data directory - you have to do that manually. The download_chirps_monthly function comes with several useful options. You can specify months and years you want to download (the default is to download everything there is). Moreover, the function automatically looks up which months have been downloaded previously and only loads the data for months that you are still missing. If you want to re-download and overwrite existing files, you can set update = FALSE. The CHIRPS data is on the very high spatial resolution of 0.05 degree lon/lat. While this makes for great-looking plots, it also means that the entire CHIRPS data is roughly 800 MB on disk, even though it is just monthly means. Moreover loading and processing this data can take a long time. To avoid this, the function provides you options to derive an upscaled version with a coarser spatial resolution (default is 0.5 degree lon/lat). The three possible options are resolution = 'both': This downloads the original data and additionally derives an upscaled version that is easier to work with. This is recommended when you have a bit over 800 MB of disk space to spare. resolution = 'low': Downloads the file and upscales it before saving. Only the coarse resolution is kept. In this format, the entire data is roughly 8 MB on disk. resolution = 'high': Downloads only the original data, and does not upscale. You need roughly 800 MB. By default, the function downloads only data for the greater-horn-of-Africa area. You can change this setting to download larger datasets such as Africa or even global, see function documentation, but be wary of long download times and disk storage. After having downloaded the chirps data, you can load it using the function load_chirps: dt = load_chirps() print(dt) ## lon lat prec year month ## 1: 21.5 -12.0 7.3370427 1981 1 ## 2: 22.0 -12.0 6.9814926 1981 1 ## 3: 22.5 -12.0 7.3014801 1981 1 ## 4: 23.0 -12.0 9.0318960 1981 1 ## 5: 23.5 -12.0 9.0771118 1981 1 ## --- ## 2117916: 49.5 22.5 0.2111690 2022 4 ## 2117917: 50.0 22.5 0.2262906 2022 4 ## 2117918: 50.5 22.5 0.2094155 2022 4 ## 2117919: 51.0 22.5 0.1797819 2022 4 ## 2117920: 51.5 22.5 0.1534985 2022 4 # example plot pp = ggplot_dt(dt[year == 2022 &amp; month == 1],high = &#39;blue&#39;,midpoint = 0) plot(pp) By default, the upscaled data is loaded (which is smaller in memory and loads faster) if it is available. Moreover, the function provides options to only load subsets of the data, and to load the data in the original high resolution (if you kept it by setting resolution = 'both' in download_chirps()): dt = load_chirps(years = 2022,months = 1,us = FALSE) print(dt) ## lon lat prec year month ## 1: 21.50 22.475 0.010631205 2022 1 ## 2: 21.55 22.475 0.010624977 2022 1 ## 3: 21.60 22.475 0.010612711 2022 1 ## 4: 21.65 22.475 0.010597722 2022 1 ## 5: 21.70 22.475 0.005510498 2022 1 ## --- ## 414686: 51.30 -11.975 NA 2022 1 ## 414687: 51.35 -11.975 NA 2022 1 ## 414688: 51.40 -11.975 NA 2022 1 ## 414689: 51.45 -11.975 NA 2022 1 ## 414690: 51.50 -11.975 NA 2022 1 # example plot pp = ggplot_dt(dt,high = &#39;blue&#39;,midpoint = 0) plot(pp) ## Warning: Raster pixels are placed at uneven horizontal intervals and will be ## shifted. Consider using geom_tile() instead. ## Warning: Raster pixels are placed at uneven vertical intervals and will be ## shifted. Consider using geom_tile() instead. "],["data-examples.html", "4 Reshaping data", " 4 Reshaping data For forecast validation, the ideal data format is to have all your fore- and hindcasts in the same data table, alongside the corresponding observations. So one column of forecasts, one column of observations and several columns of dimension variables (e.g. year, month, lon,lat). However, this is rarely how your netcdf-data looks like: you’ll often have different netcdfs for observations and fore-/hindcasts. They might, moreover have different units, different missing values, different variable names etc. So to get your data into the preferred shape, you either need to manipulate the netcdf files beforehand, to get exactly the data table you want from netcdf_to_dt, or you can extract several data tables and do the required manipulations in R, using SeaVal and data.table. In this section we show a few examples how to do this. 4.0.1 Example 1: cross-validation data We first consider a crossvalidation dataset, containing predictions for the February-April rainfall. # get the two CV-files: fn_pred = &quot;CrossValidatedPredictedRain_Feb-Apr_Feb2021.nc&quot; dt_pred = netcdf_to_dt(paste0(data_dir,fn_pred)) # here data_dir is the local path to the data (not shown) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/CrossValidatedPredictedRain_Feb-Apr_Feb2021.nc (NC_FORMAT_CLASSIC): ## ## 1 variables (excluding dimension variables): ## float prec[lon,lat,time] ## lead: 0 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 1 ## _FillValue: -9999 ## ## 3 dimensions: ## time Size:35 *** is unlimited *** ## units: months since 1981-01-01 ## calendar: standard ## _FillValue: 9.96920996838687e+36 ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ## 5 global attributes: ## MonInit_month: 2 ## valid_time: Feb-Apr ## creation_date: Mon Feb 15 06:59:57 EAT 2021 ## Conventions: None ## title: Cross Validated Predicted Rainfall Total (mm) # let&#39;s look at the data: print(dt_pred) ## lon lat time prec ## 1: 20.5 -13.5 13 NA ## 2: 21.0 -13.5 13 NA ## 3: 21.5 -13.5 13 NA ## 4: 22.0 -13.5 13 NA ## 5: 22.5 -13.5 13 NA ## --- ## 177866: 51.0 24.5 421 NA ## 177867: 51.5 24.5 421 NA ## 177868: 52.0 24.5 421 NA ## 177869: 52.5 24.5 421 NA ## 177870: 53.0 24.5 421 NA # it&#39;s also always good to have a look at plots: dt_plot = dt_pred[time == 13] # subset to only one time-slize, so that we can plot a map ggplot_dt(dt_plot,&#39;prec&#39;) Next we need observations to compare the predictions to. For this first example, we have a prepared netcdf with the observations available: fn_obs = &quot;ObservedRain_Feb-Apr_Feb2021.nc&quot; dt_obs = netcdf_to_dt(paste0(data_dir,fn_obs)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/ObservedRain_Feb-Apr_Feb2021.nc (NC_FORMAT_CLASSIC): ## ## 1 variables (excluding dimension variables): ## float prec[lon,lat,time] ## lead: 0 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 0 ## _FillValue: -9999 ## ## 3 dimensions: ## time Size:35 *** is unlimited *** ## units: months since 1981-01-01 ## calendar: standard ## _FillValue: 9.96920996838687e+36 ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ## 5 global attributes: ## MonInit_month: 2 ## valid_time: Feb-Apr ## creation_date: Mon Feb 15 06:59:57 EAT 2021 ## Conventions: None ## title: Observed Rainfall Total (mm) Now we have two data tables, one with predictions and one with observations. We want to merge them together. There are two main functions for merging data tables: rbindlist and merge. The function rbindlist takes several data tables, all with the same columns, and just appends them. This is appropriate when your data tables contain the same type of information, but for different coordinates. For example, if you have a data table with observed precipitation for 1990-2020 and a second data table with observed precipitation for 2021-2022. In our example we have two data tables but they contain different types of information (the first contains predictions, the second observations). However, they contain them at the same coordinates (meaning at the same locations specified by lon/lat, and for the same months specified by time). Such data tables are joined by the function merge. Before we join predictions and observations, we should rename their columns, though: Both of them currently have a column called prec, which contains the observations in dt_obs and the predictions in dt_pred. setnames(dt_pred,&#39;prec&#39;,&#39;prediction&#39;) setnames(dt_obs,&#39;prec&#39;,&#39;observation&#39;) dt = merge(dt_pred,dt_obs, by = c(&#39;lon&#39;,&#39;lat&#39;,&#39;time&#39;)) print(dt) ## lon lat time prediction observation ## 1: 20.5 -13.5 13 NA NA ## 2: 20.5 -13.5 25 NA NA ## 3: 20.5 -13.5 37 NA NA ## 4: 20.5 -13.5 49 NA NA ## 5: 20.5 -13.5 61 NA NA ## --- ## 177866: 53.0 24.5 373 NA NA ## 177867: 53.0 24.5 385 NA NA ## 177868: 53.0 24.5 397 NA NA ## 177869: 53.0 24.5 409 NA NA ## 177870: 53.0 24.5 421 NA NA The by-argument of the merge function identifies the columns that are present in both data tables. These are typically the columns specifying coordinates. We now have prediction and observation side by side as we wanted. However, we see that also coordinates with missing values are dragged along (where both the prediction and the observation is NA). Let’s remove them: dt = dt[!is.na(prediction)] Also, the time column is not really easy to read. Looking at the information printed out by netcdf_to_dt above tells us that the unit of time in the netcdf is months since 1981-01-01. SeaVal has a function called MSD_to_YM that converges time from this ‘months-since-date’ (MSD) format to years and months (YM), which is typically much more useful: dt = MSD_to_YM(dt, timecol = &#39;time&#39;, # what is the column called that contains the time-since-date coordinates? origin = &#39;1981-01-01&#39;) # (the origin was documented in the netcdf, see above.) print(dt) ## lon lat prediction observation year month ## 1: 20.5 -11.5 316.19452 369.36932 1982 2 ## 2: 20.5 -11.5 316.20178 252.47144 1983 2 ## 3: 20.5 -11.5 317.43375 267.44031 1984 2 ## 4: 20.5 -11.5 313.30789 332.10236 1985 2 ## 5: 20.5 -11.5 318.12195 343.65460 1986 2 ## --- ## 79745: 51.5 22.5 25.44651 19.71902 2012 2 ## 79746: 51.5 22.5 25.59836 27.55773 2013 2 ## 79747: 51.5 22.5 26.03941 25.14965 2014 2 ## 79748: 51.5 22.5 26.03053 22.23634 2015 2 ## 79749: 51.5 22.5 26.00327 34.84376 2016 2 Now the data table looks much better and contains prediction and observation side by side. The column ordering is a bit weird with predictions and observations in the middle, but this usually should not matter. In section 5.3 we continue this cross-validation example and show how to evaluate the predictions. 4.0.2 Example 2: Tercile forecasts and upscaling In the first example we were lucky that our observations and predictions were of the same format, which is not always the case. We will now look at a more complex example where we prepare a typical tercile forecast for precipitation. We consider again the 2021 MAM season as example. Let’s get started with collecting the prediction and corresponding observations: # predictions: dt = netcdf_to_dt(paste0(data_dir,&#39;PredictedProbabilityRain_Mar-May_Feb2021_new.nc&#39;), verbose = 0) # suppresses that the function prints all the netcdf-information print(dt) ## lon lat normal above below ## 1: 20.5 -13.5 NA NA NA ## 2: 20.5 -13.0 NA NA NA ## 3: 20.5 -12.5 NA NA NA ## 4: 20.5 -12.0 NA NA NA ## 5: 20.5 -11.5 34.11535 33.56262 32.32204 ## --- ## 5078: 53.0 22.5 NA NA NA ## 5079: 53.0 23.0 NA NA NA ## 5080: 53.0 23.5 NA NA NA ## 5081: 53.0 24.0 NA NA NA ## 5082: 53.0 24.5 NA NA NA # observation: dt_obs = netcdf_to_dt(paste0(data_dir,&#39;ObservedChirpsRainTotal_MAM2021.nc&#39;), vars = &#39;precip&#39;, # The netcdf file contains multiple variables, # we only want precip. verbose = 1) # This option only prints the units, which are usually the most important part: ## Units: ## precip: mm/day ## longitude: degrees_east ## latitude: degrees_north ## time: days since 1980-1-1 0:0:0 ## bnds: print(dt_obs) ## longitude latitude time precip ## 1: 21.825 -11.675 15080.5 249.09737 ## 2: 21.875 -11.675 15080.5 255.98584 ## 3: 21.925 -11.675 15080.5 268.24506 ## 4: 21.975 -11.675 15080.5 285.27295 ## 5: 22.025 -11.675 15080.5 259.53290 ## --- ## 401964: 51.175 22.225 15080.5 20.28087 ## 401965: 51.225 22.225 15080.5 20.08590 ## 401966: 51.275 22.225 15080.5 21.04944 ## 401967: 51.325 22.225 15080.5 21.87625 ## 401968: 51.375 22.225 15080.5 20.30952 As we can see, the observation data table looks quite different now. For example, the lon/lat columns are called longitude and latitude. If we want to visualize the data with the ggplot_dt function, we need to rename them: setnames(dt_obs,c(&#39;longitude&#39;,&#39;latitude&#39;),c(&#39;lon&#39;,&#39;lat&#39;)) Let’s now look at maps of the prediction and observation side by side pp1 = ggplot_dt(dt_obs,&#39;precip&#39;) + ggtitle(&#39;Observed MAM prec. 2021&#39;) pp2 = ggplot_dt(dt,&#39;above&#39;) + ggtitle(&#39;Predicted probability of wet season&#39;) ggpubr::ggarrange(pp1,pp2) We have two problems: First, observations and predictions are on a different spatial scale making it impossible to compare them directly. Second, the observation is only given as mm/month, and the prediction are probabilities for climatology-terciles. Therefore, we need to establish a local climatology first which requires collecting past rainfall observations. Only thereafter we can derive in which climatology-tercile the 2021 observation falls. Lets first get observations and predictions onto the same scale. For validation, it is usually more appropriate to upscale everything to the coarser scale. To this end we use the upscaling function upscale_regular_lon_lat dt_obs = upscale_regular_lon_lat(dt_obs, coarse_grid = dt, # to which grid do you want to upscale? uscols = &#39;precip&#39;) # which column contains the data for upscaling? pp3 = ggplot_dt(dt_obs,&#39;precip&#39;) + ggtitle(&#39;Upscaled MAM prec. 2021&#39;) ggpubr::ggarrange(pp3,pp2) Now, let us address the second problem, namely assessing where the precipitation was above or below normal. The observation we loaded contains the CHIRPS MAM average for 2021. As we showed in Section 3.2, the SeaVal package provides convenient functions for locally storing CHIRPS data and loading it. So we can load a 30-year reference period like this: dt_past_obs = load_chirps(years = 1990:2020, months = 3:5) print(dt_past_obs) ## lon lat prec year month ## 1: 21.5 -12.0 4.77311503 1990 3 ## 2: 22.0 -12.0 4.78173981 1990 3 ## 3: 22.5 -12.0 4.84994405 1990 3 ## 4: 23.0 -12.0 5.50729116 1990 3 ## 5: 23.5 -12.0 6.09404551 1990 3 ## --- ## 397106: 49.5 22.5 0.07670408 2020 5 ## 397107: 50.0 22.5 0.07071957 2020 5 ## 397108: 50.5 22.5 0.05828492 2020 5 ## 397109: 51.0 22.5 0.05185558 2020 5 ## 397110: 51.5 22.5 0.04811331 2020 5 As we can see, the past observations are monthly, but we want the MAM season total. Moreover, the local CHIRPS data is stored in mm/day. So let us convert the units and sum the precipitation over the season: dt_past_obs[,prec := 30*prec] # conversion to mm dt_past_obs = dt_past_obs[,.(precip = sum(prec)), by = .(lon,lat,year)] Now dt_past_obs and dt_obs look very similar and we can join them together: dt_obs[,year := 2021] dt_obs = rbindlist(list(dt_past_obs,dt_obs), use.names = TRUE) Now we can derive into which local climatology-tercile the precipitation of 2021 falls, by comparing with past observations. To this end we use the utility-function add_tercile_cat. The function establishes a climatology, and calculates into which tercile category each value falls: dt_obs = add_tercile_cat(dt_obs, by = c(&#39;lon&#39;,&#39;lat&#39;), # calculate the climatology and category separately for each location datacol = &#39;precip&#39;) print(dt_obs) ## lon lat year precip tercile_cat ## 1: 21.5 -12.0 1990 297.175501 1 ## 2: 22.0 -12.0 1990 291.388758 0 ## 3: 22.5 -12.0 1990 295.368593 0 ## 4: 23.0 -12.0 1990 320.389480 1 ## 5: 23.5 -12.0 1990 329.227399 1 ## --- ## 135638: 51.5 20.5 2021 25.209672 1 ## 135639: 51.5 21.0 2021 21.710808 0 ## 135640: 51.5 21.5 2021 23.181606 0 ## 135641: 51.5 22.0 2021 23.292844 -1 ## 135642: 51.5 10.5 2021 1.161395 -1 ggplot_dt(dt_obs[year == 2021],&#39;tercile_cat&#39;,low = &#39;red&#39;,high = &#39;blue&#39;) As we can see, the observation now contains a column tercile_cat that tells us whether the rainfall at this location in a given year was below normal (-1), normal (0) or above normal (1). For later use, we also add the local climatology: dt_obs[,clim := mean(precip),by = .(lon,lat)] Finally, we can merge observations and predictions. We only need the observation for 2021 (now that we have derived the tercile category). dt = merge(dt,dt_obs[year == 2021],by = c(&#39;lon&#39;,&#39;lat&#39;)) # transform percentage prediction to probabilities between zero and one: dt[,normal := normal/100] dt[,above := above/100] dt[,below := below/100] print(dt) ## lon lat normal above below year precip tercile_cat ## 1: 22.0 -11.5 0.2794044 0.3959641 0.3246315 2021 271.66260 -1 ## 2: 22.0 -11.0 0.3176142 0.3509704 0.3314154 2021 279.14212 -1 ## 3: 22.0 -10.5 0.2897301 0.3781255 0.3321443 2021 300.32638 -1 ## 4: 22.0 -10.0 0.3133837 0.3520903 0.3345260 2021 332.45747 0 ## 5: 22.0 -9.5 0.3076811 0.3480890 0.3442299 2021 407.19511 1 ## --- ## 3268: 51.5 20.0 NA NA NA 2021 26.43543 1 ## 3269: 51.5 20.5 NA NA NA 2021 25.20967 1 ## 3270: 51.5 21.0 NA NA NA 2021 21.71081 0 ## 3271: 51.5 21.5 NA NA NA 2021 23.18161 0 ## 3272: 51.5 22.0 NA NA NA 2021 23.29284 -1 ## clim ## 1: 311.90872 ## 2: 331.75210 ## 3: 333.75472 ## 4: 335.87600 ## 5: 350.41710 ## --- ## 3268: 25.26015 ## 3269: 24.40523 ## 3270: 22.87279 ## 3271: 24.11377 ## 3272: 27.69789 We continue to work with this dataset in Section 5.2, where we evaluate this example prediction. 4.0.3 Example: ‘corrupted’ netcdf Data handling can be messy and things can go wrong at any stage. Here, we have a look at a netcdf file where something has gone wrong: fn = &quot;PredictedProbabilityRain_Feb-Apr_Feb2021.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/PredictedProbabilityRain_Feb-Apr_Feb2021.nc (NC_FORMAT_CLASSIC): ## ## 3 variables (excluding dimension variables): ## float below[lon,lat] ## lead: 0 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 0 ## _FillValue: -1 ## float normal[ncl4,ncl3] ## _FillValue: -1 ## float above[lon,lat] ## lead: 0 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 2 ## _FillValue: -1 ## ## 5 dimensions: ## time Size:0 *** is unlimited *** (no dimvar) ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ncl3 Size:77 (no dimvar) ## ncl4 Size:66 (no dimvar) ## ## 6 global attributes: ## units: mm ## MonInit_month: 2 ## valid_time: Mar-May ## creation_date: Mon Feb 15 06:59:57 EAT 2021 ## Conventions: None ## title: Predicted Tercile probability ## Error in netcdf_to_dt(paste0(data_dir, fn)): Your file has variables with disjoint dimensions, which should not be stored in a single data table. Either set trymerge to FALSE or select variables with overlapping dimensions in vars. The netcdf_to_dt function prints out the netcdf information, and then crashes with the error message above, saying that we have disjoint dimension variables for some variables. Indeed, looking at the printed out netcdf-description, we have three variables (below,normal,above), and while ‘below’ and ‘above’ are indexed by ‘lon’ and ‘lat’, ‘normal’ is indexed by ‘ncl3’ and ‘ncl4’. As the error message suggests, we can set trymerge to FALSE, making netcdf_to_dt return a list of data tables, rather than a single data table. dt_list = netcdf_to_dt(paste0(data_dir,fn),trymerge = FALSE,verbose = 0) print(dt_list) ## [[1]] ## lon lat below ## 1: 20.5 -13.5 NA ## 2: 21.0 -13.5 NA ## 3: 21.5 -13.5 NA ## 4: 22.0 -13.5 NA ## 5: 22.5 -13.5 NA ## --- ## 5078: 51.0 24.5 NA ## 5079: 51.5 24.5 NA ## 5080: 52.0 24.5 NA ## 5081: 52.5 24.5 NA ## 5082: 53.0 24.5 NA ## ## [[2]] ## ncl4 ncl3 normal ## 1: 1 1 NA ## 2: 2 1 NA ## 3: 3 1 NA ## 4: 4 1 NA ## 5: 5 1 NA ## --- ## 5078: 62 77 NA ## 5079: 63 77 NA ## 5080: 64 77 NA ## 5081: 65 77 NA ## 5082: 66 77 NA ## ## [[3]] ## lon lat above ## 1: 20.5 -13.5 NA ## 2: 21.0 -13.5 NA ## 3: 21.5 -13.5 NA ## 4: 22.0 -13.5 NA ## 5: 22.5 -13.5 NA ## --- ## 5078: 51.0 24.5 NA ## 5079: 51.5 24.5 NA ## 5080: 52.0 24.5 NA ## 5081: 52.5 24.5 NA ## 5082: 53.0 24.5 NA We see that ‘ncl3’ and ‘ncl4’ have different values than ‘lon’ and ‘lat’, apparently they are meaningless indexing integers. However, the three data.tables are of the same size, and we can hope that the ‘below’ data table is arranged in the same row-ordering than the others. If this is the case, we can simply extract the ‘normal’ column from it (as vector) and attach it to one of the others. Let’s try: dt = dt_list[[1]] normal_probs_as_vector = dt_list[[2]][,normal] dt[,normal := normal_probs_as_vector] ggplot_dt(dt,&#39;normal&#39;) Plotting is usually a great way to see whether data got arranged correctly: Here, we can be fairly certain it did, simply because the missing values in the ‘normal’ vector are at the locations where they should be (over water and dry regions). If the ordering would have been differently, these would likely be all over the place. However, let’s run another test to be certain: # attach the &#39;above&#39;-data table: dt = merge(dt,dt_list[[3]],by = c(&#39;lon&#39;,&#39;lat&#39;)) print(dt) ## lon lat below normal above ## 1: 20.5 -13.5 NA NA NA ## 2: 20.5 -13.0 NA NA NA ## 3: 20.5 -12.5 NA NA NA ## 4: 20.5 -12.0 NA NA NA ## 5: 20.5 -11.5 31.13112 35.07441 33.79448 ## --- ## 5078: 53.0 22.5 NA NA NA ## 5079: 53.0 23.0 NA NA NA ## 5080: 53.0 23.5 NA NA NA ## 5081: 53.0 24.0 NA NA NA ## 5082: 53.0 24.5 NA NA NA # if the ordering of the &#39;normal&#39; column was correct, we have below + normal + above = 100%: check = rowSums(dt[,.(below,normal,above)]) print(check[1:20]) ## [1] NA NA NA NA 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 ## [20] 100 mean(check[!is.na(check)]) ## [1] 100 This shows that the ordering was correct. We also could have solved this differently, by using \\(\\text{below} + \\text{normal} + \\text{above} = 100\\%\\) directly: # only extract &#39;below&#39; and &#39;above&#39;: dt = netcdf_to_dt(paste0(data_dir,fn), vars = c(&#39;below&#39;,&#39;above&#39;),verbose = 0) print(dt) ## lon lat below above ## 1: 20.5 -13.5 NA NA ## 2: 20.5 -13.0 NA NA ## 3: 20.5 -12.5 NA NA ## 4: 20.5 -12.0 NA NA ## 5: 20.5 -11.5 31.13112 33.79448 ## --- ## 5078: 53.0 22.5 NA NA ## 5079: 53.0 23.0 NA NA ## 5080: 53.0 23.5 NA NA ## 5081: 53.0 24.0 NA NA ## 5082: 53.0 24.5 NA NA dt[,normal := 100 - below - above] ggplot_dt(dt,&#39;normal&#39;) 4.0.4 Example: preparing data for evaluating exceedence probabilities Here we show how to prepare data for evaluating exceedence probabilities, see Section 5.4. fn = &#39;PrecRegPeXcd_3monthSeasonal.nc&#39; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/PrecRegPeXcd_3monthSeasonal.nc (NC_FORMAT_CLASSIC): ## ## 1 variables (excluding dimension variables): ## float pexcd[lon,lat,model,lead,rthr] ## thrhold4: 400 ## thrhold3: 350 ## thrhold2: 300 ## thrhold1: 200 ## units: % ## _FillValue: -9999 ## ## 6 dimensions: ## time Size:0 *** is unlimited *** (no dimvar) ## rthr Size:4 ## lead Size:6 ## units: months since 2021-2-1 0:0 ## model Size:9 ## names: GEM-NEMO CanCM4i NASA-GEOSS2S GFDL-SPEAR COLA-RSMAS-CCSM4 NCEP-CFSv2 ECMWF Meteo_France UKMO ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ## 5 global attributes: ## modelnames: GEM-NEMO CanCM4i NASA-GEOSS2S GFDL-SPEAR COLA-RSMAS-CCSM4 NCEP-CFSv2 ECMWF Meteo_France UKMO ## nmodels: 9 ## initial_time: Feb2021 ## creation_date: Thu Feb 25 19:58:57 EAT 2021 ## title: Forecast probabilities of Exceedance print(dt) ## lon lat model lead rthr pexcd ## 1: 20.5 -13.5 0 0 0 NA ## 2: 21.0 -13.5 0 0 0 NA ## 3: 21.5 -13.5 0 0 0 NA ## 4: 22.0 -13.5 0 0 0 NA ## 5: 22.5 -13.5 0 0 0 NA ## --- ## 1097708: 51.0 24.5 8 5 3 NA ## 1097709: 51.5 24.5 8 5 3 NA ## 1097710: 52.0 24.5 8 5 3 NA ## 1097711: 52.5 24.5 8 5 3 NA ## 1097712: 53.0 24.5 8 5 3 NA # first, note that the &#39;model&#39;, &#39;rthr&#39;, and &#39;month&#39; column do not make much sense before we insert # the information we gather from the netcdf description above: modelnames = c(&#39;GEM-NEMO&#39;, &#39;CanCM4i&#39;, &#39;NASA-GEOSS2S&#39;, &#39;GFDL-SPEAR&#39;, &#39;COLA-RSMAS-CCSM4&#39;, &#39;NCEP-CFSv2&#39;, &#39;ECMWF&#39;, &#39;Meteo_France&#39;, &#39;UKMO&#39;) thresholds = c(200,300,350,400) dt[,model := modelnames[model + 1]] dt[,rthr := thresholds[rthr + 1]] dt[,month :=lead + 2][,lead:=NULL] Ultimately, we want to compare the skill of these models to a climatological forecast. The climatological forecast for the exceedence probability is just the fraction of observed years where the threshold was exceeded. To calculate this, we require past observations. So let us load chirps again, only for the months contained in dt: dt_chirps = load_chirps(months = unique(dt[,month])) dt_chirps[,prec:=30*prec] # convert to mm In order to get the climatological exceedence probabilities, we can use the following function: clim_fc = climatology_threshold_exceedence(dt_chirps, o = &#39;prec&#39;, thresholds = unique(dt[,rthr]), by = c(&#39;month&#39;,&#39;lon&#39;,&#39;lat&#39;)) print(clim_fc) ## month lon lat year pexcd threshold ## 1: 2 21.5 -12.0 1981 0.3414634 200 ## 2: 2 22.0 -12.0 1981 0.4634146 200 ## 3: 2 22.5 -12.0 1981 0.5121951 200 ## 4: 2 23.0 -12.0 1981 0.6585366 200 ## 5: 2 23.5 -12.0 1981 0.5609756 200 ## --- ## 4304156: 7 49.5 22.5 2022 0.0000000 400 ## 4304157: 7 50.0 22.5 2022 0.0000000 400 ## 4304158: 7 50.5 22.5 2022 0.0000000 400 ## 4304159: 7 51.0 22.5 2022 0.0000000 400 ## 4304160: 7 51.5 22.5 2022 0.0000000 400 Note that we passed the thresholds given in dt. The by argument tells the function what columns to group by when computing the climatology. Finally, we need to merge the predictions, the climatological forecast and the observation into one data table. Since we only have predictions for 2021, it is enough to provide the climatology forecast and observation for 2021 as well. Also note that we have predictions for more months than observations (at the time this is written), so we cut the predictions for June and July out - we cannot evaluate predictions we don’t know the outcome for. setnames(clim_fc,c(&#39;pexcd&#39;,&#39;threshold&#39;),c(&#39;clim&#39;,&#39;rthr&#39;)) dt = merge(dt,clim_fc[year == 2021,],by = c(&#39;lon&#39;,&#39;lat&#39;,&#39;month&#39;,&#39;rthr&#39;)) dt = merge(dt,dt_chirps[year == 2021],by = c(&#39;lon&#39;,&#39;lat&#39;,&#39;month&#39;,&#39;year&#39;)) #finally, for evaluation we generally work with probabilities between 0 and 1, not percentages: range(dt[,pexcd],na.rm = TRUE) # confirm that the data table contains percentages at the moment... ## [1] 0 100 dt[,pexcd := pexcd/100] #... and correct print(dt) ## lon lat month year rthr model pexcd clim prec ## 1: 21.5 -12.0 2 2021 200 GEM-NEMO 0.996 0.3170732 213.685669 ## 2: 21.5 -12.0 2 2021 200 CanCM4i 0.995 0.3170732 213.685669 ## 3: 21.5 -12.0 2 2021 200 NASA-GEOSS2S 0.996 0.3170732 213.685669 ## 4: 21.5 -12.0 2 2021 200 GFDL-SPEAR 0.990 0.3170732 213.685669 ## 5: 21.5 -12.0 2 2021 200 COLA-RSMAS-CCSM4 0.993 0.3170732 213.685669 ## --- ## 922316: 51.5 22.5 7 2021 400 COLA-RSMAS-CCSM4 0.000 0.0000000 9.597914 ## 922317: 51.5 22.5 7 2021 400 NCEP-CFSv2 0.000 0.0000000 9.597914 ## 922318: 51.5 22.5 7 2021 400 ECMWF NA 0.0000000 9.597914 ## 922319: 51.5 22.5 7 2021 400 Meteo_France NA 0.0000000 9.597914 ## 922320: 51.5 22.5 7 2021 400 UKMO NA 0.0000000 9.597914 How to evaluate the predictions from here is discussed in Section 5.4. "],["validation.html", "5 Validation 5.1 Evaluating Tercile Forecasts 5.2 Scores for full tercile forecasts 5.3 Evaluating cross-validation predictions 5.4 Exceedence probabilities 5.5 Temperature", " 5 Validation In this section we give examples how to evaluate seasonal forecasts with SeaVal. One of the key tasks addressed by SeaVal is the evaluation of tercile probability forecasts, but also other forecast types are supported. We recommend to read the WMO recommendations on evaluating Seasonal Climate Forecasts, which discusses in detail aspects of evaluating tercile forecasts. 5.1 Evaluating Tercile Forecasts One of the main products disseminated at GHACOFs are probabilistic forecasts whether the coming season will see a below normal-, normal-, or above normal amount of rainfall. These three categories are defined by climatological terciles, below normal meaning that the the year was dryer than 2/3 of all observed years in a climatological reference period. Therefore, we call these type of predictions tercile forecasts. Typically, high emphasis is put on the ‘most likely category’, according to the prediction. For example, the typical probability maps show for each gridpoint only the probability of this category. From an evaluation perspective, however, it is preferable to not only consider the most likely category, but to evaluate the vector of three probabilities for all categories. This vector conveys more detailed information about the forecast: Say, for example, two competing models predicted the probabilities (0.5, 0.3, 0.2) and (0.5, 0.45, 0.05), respectively (in the order below, normal, high). Say now, after observing the predicted season, it turns out that the rainfall was in fact above normal. In this case, both predictions were pretty bad, but the first model at least assigned a 20% chance to above-normal-rainfall, whereas the second model only assigned a 5% chance to that outcome. So the first prediction was substantially better than the second. However, if evaluation focuses on the category with the highest predicted probability, the two models can’t be distinguished: For both of them this category is ‘below’ with 50% probability. Therefore, considering all three probabilities of the prediction allows for better forecast evaluation. This does not mean, however, that the communication of the prediction to the public needs to contain all three probabilities, which would likely be more confusing than helpful. In the next subsection we’ll discuss how to evaluate a fully probability forecast (vector of three probabilities). In some scenarios, however, only the highest probability category (and its assigned probability) are communicated and available for evaluation. In Section @ref{eval-terciles2} we briefly discuss how forecasts can be evaluated in this case. Throughout this section we will work with the data example derived here. 5.1.1 Verification maps For getting a good idea whether a tercile forecast for a past season was good, it is a good idea to just plot the observation. And since we predict in the three categories below, normal and above, it makes sense to transform the observation to this scale and plot, where precipitation was unusual and how so. To this end we need to load more than one year of observation, in order to establish what constitutes normal rainfall for a location. This can be done by the function ver_map: # get observations (example chirps dataset for December): dt_Dec = chirps_monthly[month == 12] ver_map(dt_Dec,o = &#39;prec&#39;) Here, the brown grid points show where precipitation was below normal, blue shows grid points with normal rainfall and green shows above normal rainfall, with darker brown/green indicating more extreme observations. The ver_map function by default considers all years available in the data table to calculate the reference climatology, and plots the verification map for the last available year. So the plot above is the verification map for December 2020. These defaults can of course be changed, see functiion documentation. 5.2 Scores for full tercile forecasts By scores we mean any validation tool that returns a number. Typical examples are the ignorance score (or log-likelihood) or the ROC-score (or area under curve/AUC). Some scores such as the ignorance score directly indicate ‘goodness’ of the forecast in the sense that better forecasts achieve on average better scores. Such scores are called proper. Other scores, such as the ROC-score evaluate properties such as the resolution of the forecast, but are agnostic towards bias of the forecast. See the WMO recommendations for an overview of scores, their properties and how to use them. 5.2.1 Proper scores and proper skill scores The ignorance score evaluates forecast performance, with lower values indicating better skill: dt = dt_tercile_forecast print(dt) ## lon lat normal above below year precip tercile_cat ## 1: 22.0 -11.5 0.2794044 0.3959641 0.3246315 2021 271.66260 -1 ## 2: 22.0 -11.0 0.3176142 0.3509704 0.3314154 2021 279.14212 -1 ## 3: 22.0 -10.5 0.2897301 0.3781255 0.3321443 2021 300.32638 -1 ## 4: 22.0 -10.0 0.3133837 0.3520903 0.3345260 2021 332.45747 0 ## 5: 22.0 -9.5 0.3076811 0.3480890 0.3442299 2021 407.19511 1 ## --- ## 3268: 51.5 20.0 NA NA NA 2021 26.43543 1 ## 3269: 51.5 20.5 NA NA NA 2021 25.20967 1 ## 3270: 51.5 21.0 NA NA NA 2021 21.71081 0 ## 3271: 51.5 21.5 NA NA NA 2021 23.18161 0 ## 3272: 51.5 22.0 NA NA NA 2021 23.29284 -1 ## clim ## 1: 311.90872 ## 2: 331.75210 ## 3: 333.75472 ## 4: 335.87600 ## 5: 350.41710 ## --- ## 3268: 25.26015 ## 3269: 24.40523 ## 3270: 22.87279 ## 3271: 24.11377 ## 3272: 27.69789 # get the ignorance score igs = IGS(dt, o = &#39;tercile_cat&#39;) ggplot_dt(igs,high = &#39;darkgreen&#39;,low = &#39;purple&#39;,discrete_cs = TRUE, mn = &#39;IGS for MAM tercile forecast 2021&#39;) A common difficulty when considering proper scores is that the actual value of the score is difficult to interpret. For this purpose, scores are often transformed into skill scores. Skill scores indicate whether a forecast performed better or worse than a climatological forecast. A skill score of above zero indicates that the forecast has more skill than climatology. A skill score of 1 indicates a perfect forecast. For deriving the ignorance skill score we can simply call the IGSS function # get the ignorance score igss = IGSS(dt, o = &#39;tercile_cat&#39;) ggplot_dt(igss,high = &#39;darkgreen&#39;,low = &#39;purple&#39;,discrete_cs = TRUE,midpoint = 0, binwidth = 0.2, mn = &#39;IGS for MAM tercile forecast 2021&#39;) Green areas in the plot indicate locations where the tercile forecast performed better than climatology, purple worse. A second score similar to the ignorance score is the Multicategory Brier Score (MB). Its main advantage over the ignorance score is that it is less sensitive to outliers and always is finite (whereas the ignorance score is \\(\\infty\\) when a zero-probability event occurs). The MBS is defined as \\[\\text{MB} := (p_1 - e_1)^2 + (p_2 - e_2)^2 + (p_3 - e_3)^2.\\] Here, \\(p_1,p_2,\\) and \\(p_3\\) are the predicted probabilities for the three categories, and \\(e_i\\) is 1 if the observation falls in the \\(i\\)th category, and 0 else. For example, if the observation falls into the first category, the MB would be \\[(p_1 - 1)^2 + p_2^2 + p_3^2.\\] This score is strictly proper, meaning that it rewards calibration and accuracy. In our particular situation, the climatological forecast is uniform (since climatology is used to define the tercile categories), and the climatological forecast (1/3,1/3,1/3) always gets a MB of 2/3. It is therefore very convenient to consider the Multicategory Brier Skill Score (MBS) \\[MBS := \\frac{3}{2}(2/3 - \\text{MB}).\\] Like other skill scores, this score is normalized in the sense that a perfect forecaster attains a skill score of 1 and a climatology forecast always gets a skill score of 0. Note that, for the MBS, higher values indicate better performance, unlike for the MB (similar as for other scores such as MSE). Since the MBS is just a linear transformation of the MB, but is way easier to interpret, there is not really a reason to ever calculate the MB, and SeaVal does not contain a separate function for that. For calculating the MBS, we can call the function with the same name: # get Multicategory Brier Score: mbs = MBS(dt, o = &#39;tercile_cat&#39;) ggplot_dt(mbs,high = &#39;darkgreen&#39;,low = &#39;purple&#39;,discrete_cs = TRUE,binwidth = 0.2,midpoint = 0, mn = &#39;MBS for MAM tercile forecast 2021&#39;) As we can see, there is a large amount of agreement between the IGSS and the MBS. To see whether the forecast was overall better than climatology, we average the MBS: # check out the MBS by country: mbs = add_country_names(mbs) mean_mbs = mbs[,.(mean_mbs = mean(MBS,na.rm = T)), by = country] print(mean_mbs) ## country mean_mbs ## 1: Sudan 0.02076894 ## 2: South Sudan -0.01542756 ## 3: Rwanda 0.04052875 ## 4: Tanzania 0.01927918 ## 5: Burundi 0.09312281 ## 6: Uganda -0.02177326 ## 7: Ethiopia -0.02526435 ## 8: Kenya -0.02616993 ## 9: Eritrea -0.02673488 ## 10: Somalia -0.01600070 ## 11: Djibouti 0.03368777 Finally, let’s check whether this makes sense, by comparing climatology to the prediction: dt[,anomaly:= precip - clim] ggplot_dt(dt[year == 2021],&#39;anomaly&#39;,high = &#39;blue&#39;,low = &#39;red&#39;,midpoint = 0, mn = &#39;observed 2021 MAM precip anomaly&#39;) # or, as discrete plot: pp1 = ggplot_dt(dt[year == 2021],&#39;anomaly&#39;, high = &#39;blue&#39;,low = &#39;red&#39;,midpoint = 0, rr = c(-100,100),discrete_cs = TRUE,breaks = seq(-100,100,40), mn = &#39;observed 2021 MAM precip anomaly&#39;) # also, let&#39;s plot the predicted probabilities: pp2 = ggplot_dt(dt,&#39;below&#39;,midpoint = 0.33,discrete_cs = TRUE,binwidth = 0.05,mn = &#39;predicted probability below&#39;) pp3 = ggplot_dt(dt,&#39;normal&#39;,midpoint = 0.33,discrete_cs = TRUE,binwidth = 0.05,mn = &#39;predicted probability normal&#39;) pp4 = ggplot_dt(dt,&#39;above&#39;,midpoint = 0.33,discrete_cs = TRUE,binwidth = 0.05,mn = &#39;predicted probability above&#39;) ggpubr::ggarrange(pp1,pp2,pp3,pp4,ncol = 4) As we can see, the season was very wet overall. The prediction was overall wet as well, especially over the western part of the considered region, where the prediction also got assigned a positive MBS. 5.2.2 Evaluation when only the highest probability category is avaliable As argued above, it is preferrable to evaluate tercile forecasts that are given as full probability vector containing all three probabilities. However, we might still face scenarios where we only have the highest probability category available, e.g. some older forecasts for which only this has been saved. What can we do in this case? Intuitively, a promising candidate for a proper score seems to be the two-category-Brier score on the category with the highest probability \\[BS_{\\max} = (p_{\\max}-e_{\\max})^2,\\] where \\(p_{\\max}\\) is the probability assigned to the maximum probability category, and \\(e_{\\max} = 1\\) if the observation falls into that category and \\(0\\) else. Unfortunately, it turns out that this score is improper: it does not reward calibration and accuracy. Let us look at an example forecast for just one gridpoint: In this example, we compare a near-climatological forecast (red) with a prediction issued by a forecaster (blue). The highest probability categories are indicated by the shaded area: for the forecaster it is the ‘above normal’ category, for the climatology-forecast the ‘below normal’ category. Below the figure, the scores achieved by the forecaster and climatology are shown for all three possible outcomes. The climatology gets a better (lower) Brier score when the observation is ‘normal’ or ‘above normal’. This is paradoxical, since the forecaster assigned higher probabilities to these categorie. This highlights the improperness of the max-Brier score: When evaluating predictions with this score, the best forecast does usually not get preferred. This is unintuitive, because the (standard) Brier score is proper. However, the Brier score is designed for predictions of two-category-events with fixed categories. In the definition of \\(BS_{\\max}\\) the categories are ‘highest probability category’ vs. the rest. Therefore, the two categories depend on the forecast probabilities and therefore may vary between different predictions. This makes the Brier score improper. However, a nice application of Theorem 1 of this paper shows that there is a class of proper scoring rules that can be evaluated, when only the probability of the most likely category is known. For example, we can use the score \\[ cBS_\\max:= p^2_{\\max} - 2p_\\max e_\\max + 1.\\] Note that this score satisfies \\(cBS_\\max=BS_{\\max} - e_\\max +1\\), so it’s a corrected version of the max-Brier score which is proper and avoids the problems above. Adding \\(+1\\) in the definition of the score is not necessary but convenient: it ensures that the score is nonnegative and a perfect score is 0. Usually we want to know whether our prediction outperformed climatology. For most scores we can consider skill scores, but unfortunately this does not work here. Climatology assigns to all three categories equal probabilities (1/3), and therefore does not really have a maximum-probability-category. Thus, the definition of \\(e_\\max\\) makes no sense for a climatological forecaster. However, a reasonable viewpoint is that for a climatological forecast the maximum-probability-category can be picked at random, since all categories are getting assigned the same probability. This means that climatology achieves a score of 4/9 with probability 1/3 (when \\(e_\\max = 1\\)), but only achieves a score of 10/9 with probability 2/3. Thus, on average the climatological forecast achieves a score of \\(\\frac 1 3 \\frac 4 9 + \\frac 23 \\frac {10}9 = \\frac{24}{27}\\). A forecast that attains a \\(cBS_\\max\\) of below 24/27 performs on average better than climatology. We therefore define the ‘skill score’ \\[cBSS_\\max := 1 - \\frac{27}{24}cBS_\\max.\\] Note that this is not a skill score in the strict sense, but can be interpretet similarly: values above 0 indicate higher skill than climatology on average, with a \\(cBSS_\\max\\) of 1 corresponding to a perfect forecast. To try this out in action, let us look at the 2021 tercile forecasts # data_dir = &#39;/nr/project/stat/CONFER/Data/validation/example_data/202102/&#39; # as in section 3 fn = &#39;Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc&#39; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc (NC_FORMAT_CLASSIC): ## ## 3 variables (excluding dimension variables): ## float below[lon,lat] ## average_op_ncl: dim_avg_n over dimension(s): model ## units: ## lead: 1 ## _FillValue: -9999 ## float normal[lon,lat] ## _FillValue: -9999 ## lead: 1 ## units: ## average_op_ncl: dim_avg_n over dimension(s): model ## float above[lon,lat] ## _FillValue: -9999 ## lead: 1 ## units: ## average_op_ncl: dim_avg_n over dimension(s): model ## ## 3 dimensions: ## time Size:0 *** is unlimited *** (no dimvar) ## lat Size:381 ## units: degrees_north ## lon Size:326 ## units: degrees_east ## ## 7 global attributes: ## creation_date: Thu Feb 18 17:06:05 EAT 2021 ## Conventions: None ## source_file: Objective Forecast ## description: Obtained by averaging CPT and local regression ## title: Tercile Consolidated Objective Forecast ## history: Mon Feb 22 10:28:53 2021: ncrename -v LAT,lat Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## Mon Feb 22 10:28:43 2021: ncrename -v LON,lon Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## Mon Feb 22 10:28:26 2021: ncrename -d LON,lon Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## Mon Feb 22 10:27:42 2021: ncrename -d LAT,lat Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## NCO: netCDF Operators version 4.9.3 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco) dt = dt[!is.na(below) | !is.na(normal) | !is.na (above)] p1 = ggplot_dt(dt,data_col = &#39;below&#39;, midpoint = dt[,min(below,na.rm = TRUE)]) p2 = ggplot_dt(dt,data_col = &#39;normal&#39;, midpoint = dt[,min(normal,na.rm = TRUE)], high = &#39;darkgoldenrod&#39;) # see https://www.r-graph-gallery.com/ggplot2-color.html for an overview of color names. p3 = ggplot_dt(dt,data_col = &#39;above&#39;, midpoint = dt[,min(above,na.rm = TRUE)], high = &#39;darkgreen&#39;) ggarrange(p1,p2,p3,ncol = 3) ## Warning: Raster pixels are placed at uneven horizontal intervals and will be ## shifted. Consider using geom_tile() instead. ## Warning: Raster pixels are placed at uneven vertical intervals and will be ## shifted. Consider using geom_tile() instead. ## Warning: Raster pixels are placed at uneven horizontal intervals and will be ## shifted. Consider using geom_tile() instead. ## Warning: Raster pixels are placed at uneven vertical intervals and will be ## shifted. Consider using geom_tile() instead. ## Warning: Raster pixels are placed at uneven horizontal intervals and will be ## shifted. Consider using geom_tile() instead. ## Warning: Raster pixels are placed at uneven vertical intervals and will be ## shifted. Consider using geom_tile() instead. In order to evaluate these forecast the high resolution CHIRPS-data of the past is missing! fn = &quot;PredictedProbabilityRain_Mar-May_Feb2021_new.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/PredictedProbabilityRain_Mar-May_Feb2021_new.nc (NC_FORMAT_NETCDF4): ## ## 3 variables (excluding dimension variables): ## float normal[lon,lat] (Contiguous storage) ## _FillValue: -1 ## float above[lon,lat] (Contiguous storage) ## _FillValue: -1 ## lead: 1 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 2 ## float below[lon,lat] (Contiguous storage) ## _FillValue: -1 ## lead: 1 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 0 ## ## 2 dimensions: ## lat Size:77 ## _FillValue: NaN ## units: degrees_north ## lon Size:66 ## _FillValue: NaN ## units: degrees_east dt[,normal := normal/100][,above := above/100][,below := below/100] 5.3 Evaluating cross-validation predictions Here we evaluate the cross-validation data prepared in Section 4.0.1. The data table contains observations for past years for the FMA season, along with ‘best-guess’-predictions, meaning that they are single numbers, not probabilities: print(dt_cv) ## lon lat prediction observation year month ## 1: 20.5 -11.5 316.19452 369.36932 1982 2 ## 2: 20.5 -11.5 316.20178 252.47144 1983 2 ## 3: 20.5 -11.5 317.43375 267.44031 1984 2 ## 4: 20.5 -11.5 313.30789 332.10236 1985 2 ## 5: 20.5 -11.5 318.12195 343.65460 1986 2 ## --- ## 79745: 51.5 22.5 25.44651 19.71902 2012 2 ## 79746: 51.5 22.5 25.59836 27.55773 2013 2 ## 79747: 51.5 22.5 26.03941 25.14965 2014 2 ## 79748: 51.5 22.5 26.03053 22.23634 2015 2 ## 79749: 51.5 22.5 26.00327 34.84376 2016 2 Such predictions are often called point forecasts, whereas forecasts specifying probabilities are called probabilistic. We already have the data in the shape we want it to be, containing both predictions and observations as one column each. Let’s have a look at the bias in our predictions: ### check out local biases: bias_dt = dt_cv[,.(bias = mean(prediction - observation)), by = .(lon,lat)] # grouping by lon,lat, and season means that the mean is taken over all years. bias_dt[,range(bias)] # get an idea of the range for plotting ## [1] -10.81321 13.11778 rr = c(-15,15) # fix range, to make plots comparable ggplot_dt(bias_dt, data_col = &#39;bias&#39;, rr = rr, # fix range to make it comparable to pp2 mn = &#39;bias of FMA prediction&#39;, midpoint = 0) For evaluating the locally varying skill of these predictions we can calculate the average square error per location and compare it to the square error we would get by predicting local climatology, i.e., just the mean precipitation for that location. This is called the mean square error skill score (MSES) and is calculated by the function MSES. For fair comparison, the climatology needs to be calculated leave-one-year-out: For example, a climatological prediction for 2021 prediction would be the mean precipitation over all years except 2021. Otherwise, the climatological forecast uses information that would not be available in a prediction setting, which inflates the skill of the climatology forecast. ### analyze mean square error skill scores msess = MSES(dt_cv, f = &#39;prediction&#39;, # column name of forecasts o = &#39;observation&#39;, # column name of observations by = c(&#39;lon&#39;,&#39;lat&#39;)) # the skill scores should be computed for each location separately # plot results: ggplot_dt(msess, data_col = &#39;MSES&#39;, midpoint = 0, # center color scale, white is 0 mn = &#39;MSE skill score, FMA&#39;) As for all skill scores, positive values indicate that the prediction has higher skill than climatology, negative values indicates lower skill. Skill scores are moreover ‘standardized’ such that a score of 1 corresponds to a perfect forecast. Most evaluation functions in SeaVal require similar input as MSES: * dt: a data table containing both observations and predictions. * f,o: the column names of the predictions and observation. * by: the column names for dimension variables to group by. [Add more context here] Note that there is also a (faster) function MSE if we’re not interested in skill scores, but simply want to compute MSEs. Both function can also handle ensemble predictions, see function documentation. If we want to analyze results by countries, we can use the function add_country_names that adds a column with country names to the data table: # check out average MSEs and MSESSs per country: msess = add_country_names(msess) print(msess) ## lon lat MSE clim_MSE MSES country ## 1: 24.5 8.5 166.01823 160.95057 -0.0314858375 South Sudan ## 2: 25.0 8.0 157.70201 155.21241 -0.0160399415 South Sudan ## 3: 25.0 8.5 184.12923 175.97631 -0.0463296523 South Sudan ## 4: 25.5 7.5 318.41059 315.81470 -0.0082196638 South Sudan ## 5: 25.5 8.0 189.80862 189.96845 0.0008413415 South Sudan ## --- ## 1231: 48.5 11.0 68.40813 72.26785 0.0534084478 Somalia ## 1232: 49.0 6.5 202.11711 216.18040 0.0650534734 Somalia ## 1233: 49.0 7.0 153.96742 162.97361 0.0552616643 Somalia ## 1234: 49.5 11.0 74.21040 76.48522 0.0297419712 Somalia ## 1235: 50.0 11.0 181.27647 184.42122 0.0170519749 Somalia msess_by_country = msess[,.(MSE = mean(MSE), MSES = mean(MSES)), by = country] # take averages by country print(msess_by_country) ## country MSE MSES ## 1: South Sudan 622.6657 0.029073419 ## 2: Rwanda 1695.8937 0.130467978 ## 3: Tanzania 4011.6931 0.030148166 ## 4: Burundi 2195.6404 0.109954193 ## 5: Uganda 1369.9684 0.062205385 ## 6: Ethiopia 1557.5682 0.068145290 ## 7: Kenya 2173.5858 0.066719651 ## 8: Sudan 216.8926 -0.021270474 ## 9: Eritrea 393.7713 0.007646318 ## 10: Somalia 1183.0632 0.040397831 ## 11: Djibouti 121.1750 0.078021693 Skill scores strongly depend on the skill of the climatological prediction, see Section 5.4. This makes it somewhat problematic to average them in space, as skill scores for different grid points with different climatologies have different meanings. A more appropriate way to see whether the prediction outperformed climatology on average for a given country is by considering average score differences: # positive values indicate better performance than climatology: msess[,.(score_diff = mean(clim_MSE - MSE)),by = country] ## country score_diff ## 1: South Sudan 27.289033 ## 2: Rwanda 283.252101 ## 3: Tanzania 82.175135 ## 4: Burundi 273.488506 ## 5: Uganda 89.460627 ## 6: Ethiopia 131.532177 ## 7: Kenya 166.101084 ## 8: Sudan -4.517323 ## 9: Eritrea -5.201654 ## 10: Somalia 58.001462 ## 11: Djibouti 11.940107 The MSE (and its associated skill score) penalizes both systematic forecast errors (i.e. biases) and non-systematic forecast errors. The latter are a consequence of general forecast uncertainty and there is no easy way to reduce them. Biases, however, can often be removed through statistical post-processing, and it is therefore interesting to consider measures for forecast performance that penalize only non-systematic forecast errors, thus giving an idea of the potential skill of a forecast system. The standard metric to assess the potential skill is the Pearson correlation coefficient (PCC). This is the usual correlation coefficient where forecasts and observations are standardized by their respective climatological means and standard deviations, and then the average product of these standardized variables is calculated. The function PCC performs these calculations and is used in the same way as MSES above. ### calculate Pearson correlation coefficients pcc = PCC(dt_cv, f = &#39;prediction&#39;, # column name of forecasts o = &#39;observation&#39;, # column name of observations by = c(&#39;lon&#39;,&#39;lat&#39;)) # the correlation coefficient should be computed for each location separately # the maximal range for a correlation coefficient is [-1,1], but sometimes it is useful to narrow it: rr = c(-0.75,0.75) ggplot_dt(pcc, data_col = &#39;rho&#39;, rr=rr, mn = &#39;Pearson correlation coefficient, FMA&#39;) While there is no technical requirement that the forecasts and observations follow a particular probability distribution when the Pearson correlation coefficient is employed, this metric is best suited for continuous distributions (i.e. it is unlikely to encounter duplicate values) that are relatively symmetric around the mean. For shorter (e.g. weekly) accumulation periods and in dry climates, the distribution of precipitation usually becomes rather skewed and contains a number of zeros. A new metric, the coefficient of predictive ability (CPA), has recently been developed and constitutes an excellent alternative to the PCC as a measure of potential forecast skill in that situation of strongly asymmetric distributions with multiple identical values. See here for more background information about the CPA. The function CPA performs the calculations and is used in the same way as MSES and PCC above. ### calculate coefficient of predictive ability cpa = CPA(dt_cv, f = &#39;prediction&#39;, # column name of forecasts o = &#39;observation&#39;, # column name of observations by = c(&#39;lon&#39;,&#39;lat&#39;)) # the CPA should be computed for each location separately # the maximal range for the CPA is [0,1] # a value of 0.5 corresponds to no skill (more details can be found in the document under the link given above) rr = c(0,1) ggplot_dt(cpa, data_col = &#39;cpa&#39;, rr=rr, mn = &#39;Coefficient of predictive ability, FMA&#39;) Just like the MSES, PCC and CPA can be averaged by country using the function add_country_names: # check out average PCCs and CPAs per country: pcc = add_country_names(pcc) cpa = add_country_names(cpa) pcc_by_country = pcc[,.(rho = mean(rho)), by = country] cpa_by_country = cpa[,.(cpa = mean(cpa)), by = country] print(pcc_by_country) ## country rho ## 1: South Sudan -0.131322590 ## 2: Rwanda 0.304516201 ## 3: Tanzania -0.102200872 ## 4: Burundi 0.230229774 ## 5: Uganda 0.087081218 ## 6: Ethiopia 0.068491179 ## 7: Kenya 0.100172850 ## 8: Sudan -0.328970736 ## 9: Eritrea -0.169954159 ## 10: Somalia 0.003777202 ## 11: Djibouti 0.194408707 print(cpa_by_country) ## country cpa ## 1: South Sudan 0.4362882 ## 2: Rwanda 0.6468312 ## 3: Tanzania 0.4564792 ## 4: Burundi 0.6117025 ## 5: Uganda 0.5372199 ## 6: Ethiopia 0.5428733 ## 7: Kenya 0.5474916 ## 8: Sudan 0.3812325 ## 9: Eritrea 0.4131719 ## 10: Somalia 0.5254189 ## 11: Djibouti 0.6097689 5.4 Exceedence probabilities Another forecast product issued at GHACOFs are exceedence probabilities of precipitation for certain thresholds, generally related to crops important for the region. A proper scoring rule based on the predicted exceedence probability \\(p_\\text{exc}(c)\\) of a threshold \\(c\\) is the Brier score of exceedence \\[BS_{ex}(c) := (p_\\text{exc}(c) - 1\\{y&gt;c\\})^2,\\] where \\(1\\{y&gt;c\\}\\) equals 1 if the observation \\(y\\) exceeded threshold \\(c\\), and 0 else. Skill scores for comparison with a climatological forecast can be calculated in the usual way. The climatological forecast for the exceedence probability is the fraction of past observations that exceeded the threshold. In Section 4.0.4 we already derived this dataset: print(dt_prexc) ## lon lat month year rthr model pexcd clim prec ## 1: 21.5 -12.0 2 2021 200 GEM-NEMO 0.996 0.3170732 213.685669 ## 2: 21.5 -12.0 2 2021 200 CanCM4i 0.995 0.3170732 213.685669 ## 3: 21.5 -12.0 2 2021 200 NASA-GEOSS2S 0.996 0.3170732 213.685669 ## 4: 21.5 -12.0 2 2021 200 GFDL-SPEAR 0.990 0.3170732 213.685669 ## 5: 21.5 -12.0 2 2021 200 COLA-RSMAS-CCSM4 0.993 0.3170732 213.685669 ## --- ## 922316: 51.5 22.5 7 2021 400 COLA-RSMAS-CCSM4 0.000 0.0000000 9.597914 ## 922317: 51.5 22.5 7 2021 400 NCEP-CFSv2 0.000 0.0000000 9.597914 ## 922318: 51.5 22.5 7 2021 400 ECMWF NA 0.0000000 9.597914 ## 922319: 51.5 22.5 7 2021 400 Meteo_France NA 0.0000000 9.597914 ## 922320: 51.5 22.5 7 2021 400 UKMO NA 0.0000000 9.597914 This dataset contains predictions of exceedence (by different models) for several thresholds (rthr), as well as observed rainfall and a climatological prediction for the exceedence probabilities. This is everything we need to compute the \\(BS_{ex}\\)-skill score. To this end, we have the function BSS_ex_dt. If we would not have a climatological exceedence forecast available, we could have still computed the \\(BS_{ex}\\)-score using the function BS_ex_dt. This is still usefull for comparing competing models (see below), but does not tell us where the prediction is better or worse than climatology. # bss_dt = BSS_ex_dt(dt_prexc, # f = &#39;pexcd&#39;, # threshold_col = &#39;rthr&#39;, # o = &#39;prec&#39;, # by = c(&#39;model&#39;,&#39;month&#39;,&#39;lon&#39;,&#39;lat&#39;)) # # print(bss_dt[!is.na(BS_ex)]) Skill scores are generally not defined when the climatological prediction is perfect and the climatological score is zero. This happens frequently for exceedence probabilities (e.g. lines 3 and 4 in the data table above) at locations where the considered threshold has never been exceeded in the observation. Simply for plotting reasons we put the skill score to -1 in this case if the prediction scores above 0 (since the climatological prediction wwas better in this case), and to 0 if both climatology and prediction assign a probability of 0. Let us look at the skill scores by the different models for the March forecast for exceedence level 200mm: # make a list of skill score plots: # theme_set(theme_bw(base_size = 10)) # smaller font # plot_list = list() # for(mod in unique(bss_dt[,model])) # 1 plot for each model # { # plot_list = c(plot_list,list(ggplot_dt( bss_dt[model == mod &amp; month == 3 &amp; rthr == 200], # &#39;BSS_ex&#39;, # mn = mod, # high = &#39;red&#39;, # midpoint = 0, # rr= c(-1,1), # guide = guide_colorbar(title = NULL, barwidth = 75, direction = &#39;horizontal&#39;)))) # # } # # ggpubr::ggarrange(plotlist = plot_list,ncol = 3,nrow = 3,common.legend = TRUE,legend = &#39;bottom&#39;) Here, red color indicates better performance of the prediction than climatology. Large areas of the map are blue, which indicates better performance of the climatological forecast than of the prediction models. However, these are mostly areas where the observations never exceeded 200mm. Therefore, the climatological forecast issued a 0% chance of rainfall exceeding 200mm, whereas all actual prediction models issued a small positive probability and therefore performed ‘worse’. This not so much highlights a problem of the forecasts than rather a problem of skill scores, which become degenerate whenever the climatological prediction is near perfect. For comparing overall performance, we can average scores spatially. Note that, because of the above-mentioned effect, it is important not to average skill scores. However, since we have a climatology forecast in our data table, we can compute a spatially averaged score for climatology as well. Thus, we can compare whether the prediction models performed on average better or worse than climatology. # mean_scores = bss_dt[,.(BS_ex = mean(BS_ex,na.rm = T)),by = .(model,month,rthr)] # # get climatology score as well: # mean_clim_score = bss_dt[model == model[1],.(BS_ex = mean(clim_BS_ex,na.rm = T)),by = .(month,rthr)] # mean_clim_score[,model := &#39;clim&#39;] # # mean_scores = rbindlist(list(mean_scores,mean_clim_score),use.names = TRUE) # print(mean_scores) Here, every model gets assigned a single mean score for each month and each threshold (the mean score over all gridpoints). Lower values indicate better overall performance. Let us plot the data: #pp = ggplot(mean_scores) + geom_line(aes(x = month,y = BS_ex,color = model,linetype = model)) + facet_wrap(~rthr,nrow = 1) # #print(pp) The plot shows that, averaging over all grid points, a climatological forecast does much better than all the systems, which probably indicates that the systems need to be bias corrected. 5.5 Temperature In our folder of example data we also have a file containing temperature predictions. The file already contains correlations as well. Here we simply visualize these correlations as plots: fn = &#39;TrefEnsRegr_monthly.nc&#39; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/SeaVal/example_data/202102/TrefEnsRegr_monthly.nc (NC_FORMAT_CLASSIC): ## ## 6 variables (excluding dimension variables): ## float below[lon,lat,model,lead] ## units: % ## _FillValue: -9999 ## float above[lon,lat,model,lead] ## units: % ## _FillValue: -9999 ## float normal[lon,lat,model,lead] ## units: % ## _FillValue: -9999 ## float corr[lon,lat,model,lead] ## units: cor ## _FillValue: -9999 ## float tref[lon,lat,model,lead] ## units: K ## _FillValue: -9999 ## float anom[lon,lat,model,lead] ## units: K ## _FillValue: -9999 ## ## 4 dimensions: ## lon Size:66 ## units: degreesE ## long_name: lon ## lat Size:77 ## units: degreesN ## long_name: lat ## model Size:5 ## units: number ## long_name: model ## lead Size:3 ## units: month ## long_name: lead # plot correlations of predictions for all five models at all lead_times: # create list of plots: plot_list = list() for(leadtime in 1:3) { for(mod in 1:5) { plot_list = c(plot_list,list(ggplot_dt(dt[model == mod &amp; lead == leadtime], &#39;corr&#39;, rr = c(-1,1), mn = paste0(&#39;model &#39;,mod,&#39;, lead &#39;,leadtime), discrete_cs = TRUE, binwidth = 0.2, guide = guide_colorbar(title = NULL, barwidth = 75, direction = &#39;horizontal&#39;)))) } } #plot as grid: do.call(&#39;ggarrange&#39;, c(plot_list,ncol = 5,nrow = 3,common.legend = TRUE,legend = &#39;bottom&#39;)) "],["validation-1.html", "6 Validation 6.1 Matching predictions and observations 6.2 Evaluating weekly predictions of precipitation", " 6 Validation This section looks into evaluation of weekly predictions. Seaval can be used to compute evaluation metrics such as the MSE for the running forecasts. These results can be saved as netcdfs which allows to integrate the results with the East African Hazard Watch. 6.1 Matching predictions and observations Numerical weather prediction models produce forecasts on a spatial grid with a certain resolution. Similarly, satellite-based observation datasets, such as for example CHIRPS, provide estimates of observed weather on a spatial grid. It frequently happens, that the observation and predictions are on grids with different resolution. If this is the case, you need to first map the values from the different grids onto the same grid, before they can be compared. The package SeaVal allows to do that by the function upscale_lonlat. 6.2 Evaluating weekly predictions of precipitation The function eval_weekly_precip operates directly on the current format the weekly predictions are stored in. It takes the name of a folder where the predictions are stored, as well as the initialization date in the format ‘YYYYMMDD’. At ICPAC the predictions are stored under /SharedData/wrf/weekly/ "]]
